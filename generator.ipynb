{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635387aa",
   "metadata": {},
   "source": [
    "# --- Settings ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faefc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cities loaded\n"
     ]
    }
   ],
   "source": [
    "# ---- Imports ----\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "from time import perf_counter\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import umap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from hdbscan import HDBSCAN\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"umap\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib.externals.loky\")\n",
    "\n",
    "# Fast BLAS on Apple Silicon\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# OSMnx settings\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "# Layout params\n",
    "thumb_size = (600, 600)\n",
    "font_size, title_font_size = 20, 26\n",
    "panel_width = 2 * thumb_size[0] + 3 * 40\n",
    "panel_height = thumb_size[1] + 3 * font_size + 80\n",
    "\n",
    "# Fonts\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    title_font = ImageFont.truetype(\"arial.ttf\", title_font_size)\n",
    "except Exception:\n",
    "    font = ImageFont.load_default()\n",
    "    title_font = ImageFont.load_default()\n",
    "\n",
    "# Files & directories\n",
    "pdf_file = \"comparison.pdf\"\n",
    "map_dir, tax_dir, emb_dir, gra_dir, clu_dir = \"maps\", \"taxonomy\", \"embeddings\", \"graphs\", \"clusters\"\n",
    "for d in (map_dir, tax_dir, emb_dir, gra_dir, clu_dir):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---- GSD-inspired earthy mapping palette ----\n",
    "NEUTRAL = \"#CCCCCC\"\n",
    "PALETTE = [\n",
    "    \"#A4653E\",  # brighter terracotta\n",
    "    \"#D9985E\",  # lighter ochre\n",
    "    \"#88B28B\",  # fresher sage green\n",
    "    \"#69A8B2\",  # clearer teal\n",
    "    \"#B2879C\",  # livelier mauve\n",
    "    \"#6A717A\",  # lighter slate gray\n",
    "    \"#E0D3B0\",  # brighter pale stone\n",
    "    \"#9C7384\",  # stronger plum\n",
    "]\n",
    "\n",
    "city_data=[{\"name\":\"Rome\",\"country\":\"ITA\",\"coordinates\":(41.894096,12.485609),\"distance\":12000,\"group\":\"Archetypal\",\"taxonomy\":\"Radial_Implosion\",\"network\":\"drive\"},{\"name\":\"Vatican_City\",\"country\":\"VAT\",\"coordinates\":(41.902257,12.457421),\"distance\":200,\"group\":\"Archetypal\",\"taxonomy\":\"Elliptical_Implosion\",\"network\":\"all\"},{\"name\":\"Fez\",\"country\":\"MAR\",\"coordinates\":(34.065,-4.973),\"distance\":800,\"group\":\"Archetypal\",\"taxonomy\":\"Organic_Rhizome\",\"network\":\"all\"},{\"name\":\"Moscow\",\"country\":\"RUS\",\"coordinates\":(55.7558,37.6176),\"distance\":60000,\"group\":\"Archetypal\",\"taxonomy\":\"Centralized_Burst\",\"network\":\"drive\"},{\"name\":\"Medellin\",\"country\":\"COL\",\"coordinates\":(6.2518,-75.5836),\"distance\":15000,\"group\":\"Geometrical\",\"taxonomy\":\"Arc_Diagram\",\"network\":\"all\"},{\"name\":\"Palmanova\",\"country\":\"ITA\",\"coordinates\":(45.9061,13.3095),\"distance\":1500,\"group\":\"Geometrical\",\"taxonomy\":\"Radial_Convergence\",\"network\":\"all\"},{\"name\":\"Dubai\",\"country\":\"ARE\",\"coordinates\":(25.056530,55.207939),\"distance\":1000,\"group\":\"Geometrical\",\"taxonomy\":\"Segmented_Radial_Convergence\",\"network\":\"all\"},{\"name\":\"Canberra\",\"country\":\"AUS\",\"coordinates\":(-35.308188,149.124441),\"distance\":3200,\"group\":\"Geometrical\",\"taxonomy\":\"Centralized_Ring\",\"network\":\"all\"},{\"name\":\"Los_Angeles\",\"country\":\"USA\",\"coordinates\":(34.029315,-118.214444),\"distance\":800,\"group\":\"Relational\",\"taxonomy\":\"Flow_Chart\",\"network\":\"drive\"},{\"name\":\"Randstad\",\"country\":\"NLD\",\"coordinates\":(52.1,4.6),\"distance\":40000,\"group\":\"Relational\",\"taxonomy\":\"Area_Grouping\",\"network\":\"drive\"},{\"name\":\"Greater_Cairo\",\"country\":\"EGY\",\"coordinates\":(30.0444,31.2357),\"distance\":50000,\"group\":\"Relational\",\"taxonomy\":\"Circular_Ties\",\"network\":\"drive\"},{\"name\":\"Amsterdam\",\"country\":\"NLD\",\"coordinates\":(52.371,4.90),\"distance\":2000,\"group\":\"Relational\",\"taxonomy\":\"Ramification\",\"network\":\"all\"}]\n",
    "\n",
    "# --- Choose which cities to process ---\n",
    "# TARGET_CITIES = None   # None = process all cities\n",
    "TARGET_CITIES = [\"Amsterdam\", \"Canberra\"]  # uncomment to process only Amsterdam\n",
    "\n",
    "print(f\"{len(city_data)} cities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc3cf",
   "metadata": {},
   "source": [
    "# --- Graphs ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Canberra (all, r=3200m) ‚Äî saved in 13.1s\n",
      "‚úÖ Amsterdam (all, r=2000m) ‚Äî saved in 9.8s\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "    \n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "\n",
    "    if os.path.exists(gpath):\n",
    "        print(f\"üóÇÔ∏è {city['name']} skipped (already exists)\")\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    G = ox.graph_from_point(\n",
    "        city['coordinates'],\n",
    "        dist=city['distance'],\n",
    "        network_type=city['network'],\n",
    "        simplify=True,\n",
    "        retain_all=False\n",
    "    )\n",
    "    ox.save_graphml(G, gpath)\n",
    "    dt = perf_counter() - t0\n",
    "    print(f\"‚úÖ {city['name']} ({city['network']}, r={city['distance']}m) ‚Äî saved in {dt:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65636f52",
   "metadata": {},
   "source": [
    "# --- Node2Vec ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6c6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Saved Canberra (14523 nodes) in 13.7s\n",
      "   ‚úÖ Saved Amsterdam (10087 nodes) in 10.3s\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    npz_path = os.path.join(emb_dir, f\"{city['name']}.npz\")\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # largest connected component ‚Üí a single ‚Äústory world‚Äù for the walks\n",
    "    H = nx.Graph(ox.load_graphml(os.path.join(gra_dir, f\"{city['name']}.graphml\")))\n",
    "    H = H.subgraph(max(nx.connected_components(H), key=len)).copy()\n",
    "    node_list = list(H.nodes())\n",
    "\n",
    "    # Node2Vec sampler (Grover & Leskovec): biased 2nd-order random walks\n",
    "    n2v = Node2Vec(\n",
    "        H,\n",
    "        dimensions=32,          # embedding dimensionality (the space the walks learn)\n",
    "        walk_length=15,         # T: length of each 2nd-order walk\n",
    "        num_walks=8,            # Œ≥: walks launched per node (more = smoother estimates)\n",
    "        p=1.0,                  # return parameter: >1 discourages immediate backtracking; <1 encourages it\n",
    "        q=0.5,                  # in/out parameter: <1 ‚Üí BFS/homophily (stay local); >1 ‚Üí DFS/structural roles\n",
    "        workers=max(1, mp.cpu_count()-1),  # parallel samplers\n",
    "        seed=42,                # reproducible walk corpus\n",
    "        quiet=True              # hush the sampler\n",
    "    )\n",
    "\n",
    "    # Skip-gram optimizer on the walk corpus (word2vec on nodes)\n",
    "    model = n2v.fit(\n",
    "        window=5,               # context window (how far co-occurrence is trusted)\n",
    "        min_count=1,            # keep all nodes in the vocabulary\n",
    "        batch_words=128         # SGD batch size\n",
    "    )\n",
    "\n",
    "    # embeddings aligned to node_list order\n",
    "    X = np.array([model.wv[str(n)] for n in node_list])\n",
    "\n",
    "    np.savez_compressed(npz_path, X=X)\n",
    "    with open(ids_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(map(str, node_list)))\n",
    "\n",
    "    print(f\"   ‚úÖ Saved {city['name']} ({len(node_list)} nodes) in {perf_counter()-t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f0cc4",
   "metadata": {},
   "source": [
    "# --- UMAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef23608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèôÔ∏è Canberra | PCA 0.0s | UMAP 11.9s | saved embeddings/Canberra.npy\n",
      "üèôÔ∏è Amsterdam | PCA 0.0s | UMAP 3.1s | saved embeddings/Amsterdam.npy\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES is not None and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    X = np.load(os.path.join(emb_dir, f\"{city['name']}.npz\"))[\"X\"].astype(\"float32\")\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "\n",
    "    # Normalize + PCA\n",
    "    X_red = PCA(n_components=16, random_state=0).fit_transform(normalize(X, norm=\"l2\"))\n",
    "    t_pca = perf_counter()\n",
    "\n",
    "    # UMAP\n",
    "    embed = umap.UMAP(\n",
    "        n_neighbors=8,     # 8 words nicely to keep the global structure (5 leaves holes in the structure of the city)\n",
    "        min_dist=0.20,      # was 0.20; gives a nice balance between local and global structure\n",
    "        metric=\"euclidean\", # fine on normalized/PCA data\n",
    "        random_state=42,\n",
    "        n_epochs=150,\n",
    "        low_memory=True,\n",
    "    ).fit_transform(X_red)\n",
    "\n",
    "    np.save(umap_path, embed)\n",
    "    print(f\"üèôÔ∏è {city['name']} | PCA {t_pca-t0:.1f}s | UMAP {perf_counter()-t_pca:.1f}s | saved {umap_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eb360",
   "metadata": {},
   "source": [
    "# --- HDBSCAN ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3552a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèôÔ∏è Canberra | HDBSCAN 0.3s | clusters 5 | noise 6810/14523 (46.9%) ‚Üí clusters/Canberra.csv\n",
      "üèôÔ∏è Amsterdam | HDBSCAN 0.2s | clusters 6 | noise 2854/10087 (28.3%) ‚Üí clusters/Amsterdam.csv\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load UMAP embedding\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "    embed = np.load(umap_path)\n",
    "\n",
    "    # Load node ids; fallback to sequential ids if file is missing\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "    with open(ids_path) as f:\n",
    "        node_list = [line.strip() for line in f]\n",
    "\n",
    "    # Sanity check: rows must match ids count\n",
    "    assert embed.shape[0] == len(node_list), (\n",
    "        f\"Mismatch: {embed.shape[0]} embeddings vs {len(node_list)} ids for {city['name']}\"\n",
    "    )\n",
    "\n",
    "    # HDBSCAN on UMAP space (2D)\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=max(10, int(len(node_list) ** 0.70)),\n",
    "        min_samples=3,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"leaf\",\n",
    "        cluster_selection_epsilon=0.06,\n",
    "        prediction_data=False,\n",
    "        approx_min_span_tree=True,\n",
    "        gen_min_span_tree=False,\n",
    "        algorithm=\"best\",\n",
    "        core_dist_n_jobs=mp.cpu_count(),\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embed)  # -1 = noise\n",
    "\n",
    "    # Map cluster ‚Üí color using the GLOBAL PALETTE (stable order)\n",
    "    uniq = sorted(set(labels) - {-1})\n",
    "    label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "    point_colors = [label2color.get(lbl, NEUTRAL) for lbl in labels]\n",
    "\n",
    "    # Save colored embedding (for visual checks)\n",
    "    out_jpg = os.path.join(clu_dir, f\"{city['name']}.jpg\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embed[:, 0], embed[:, 1], s=1.5, c=point_colors, alpha=0.9, edgecolor='none')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_jpg, dpi=600, bbox_inches=\"tight\", format=\"jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    # Persist exact colors per node\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"node_id\", \"cluster\", \"color_hex\"])\n",
    "        for nid, lbl, col in zip(node_list, labels, point_colors):\n",
    "            w.writerow([nid, int(lbl), col])\n",
    "\n",
    "    noise = int((labels == -1).sum())\n",
    "    print(f\"üèôÔ∏è {city['name']} | HDBSCAN {perf_counter()-t0:.1f}s | clusters {len(uniq)} | noise {noise}/{len(node_list)} ({noise/len(node_list):.1%}) ‚Üí {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918d23d",
   "metadata": {},
   "source": [
    "# --- Maps ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76365b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è Canberra | map 5.2s ‚Üí maps/Canberra.png\n",
      "üó∫Ô∏è Amsterdam | map 3.4s ‚Üí maps/Amsterdam.png\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load graph\n",
    "    G = ox.load_graphml(os.path.join(gra_dir, f\"{city['name']}.graphml\"))\n",
    "\n",
    "    # Load cluster labels and the exact colors chosen earlier\n",
    "    node_cluster, node_color = {}, {}\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            nid = str(row[\"node_id\"])\n",
    "            node_cluster[nid] = int(row[\"cluster\"])\n",
    "            node_color[nid]   = row.get(\"color_hex\") or NEUTRAL\n",
    "\n",
    "    # Project and color edges: use a cluster color only when both endpoints share the same cluster; else NEUTRAL\n",
    "    G_proj = ox.project_graph(G)\n",
    "    edge_colors = [\n",
    "        (node_color.get(str(u), NEUTRAL)\n",
    "         if (node_cluster.get(str(u)) == node_cluster.get(str(v)) and\n",
    "             node_cluster.get(str(u), -1) != -1)\n",
    "         else NEUTRAL)\n",
    "        for u, v, k in G_proj.edges(keys=True)\n",
    "    ]\n",
    "\n",
    "    out_png = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    fig, ax = ox.plot_graph(\n",
    "        G_proj,\n",
    "        bgcolor=\"white\",\n",
    "        node_size=0,\n",
    "        edge_color=edge_colors,\n",
    "        edge_linewidth=0.4,\n",
    "        show=False,\n",
    "        save=True,\n",
    "        filepath=out_png,\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"üó∫Ô∏è {city['name']} | map {perf_counter()-t0:.1f}s ‚Üí {out_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9685",
   "metadata": {},
   "source": [
    "# --- Panels ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e2a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Panel created: Rome\n",
      "‚úÖ Panel created: Vatican_City\n",
      "‚úÖ Panel created: Fez\n",
      "‚úÖ Panel created: Moscow\n",
      "‚úÖ Panel created: Medellin\n",
      "‚úÖ Panel created: Palmanova\n",
      "‚úÖ Panel created: Dubai\n",
      "‚úÖ Panel created: Canberra\n",
      "‚úÖ Panel created: Los_Angeles\n",
      "‚úÖ Panel created: Randstad\n",
      "‚úÖ Panel created: Greater_Cairo\n",
      "‚úÖ Panel created: Amsterdam\n",
      "üìÑ Exported to: comparison.pdf\n"
     ]
    }
   ],
   "source": [
    "slides = []\n",
    "\n",
    "for city in city_data:\n",
    "    taxonomy_path = os.path.join(tax_dir, f\"{city['taxonomy']}.jpg\")\n",
    "    city_path     = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    clusters_path  = os.path.join(clu_dir, f\"{city['name']}.jpg\")\n",
    "\n",
    "    taxonomy_img = Image.open(taxonomy_path).convert(\"RGB\").resize(thumb_size)\n",
    "    city_img     = Image.open(city_path).convert(\"RGB\").resize(thumb_size)\n",
    "    clusters_img  = Image.open(clusters_path).convert(\"RGB\").resize(thumb_size)\n",
    "\n",
    "    images = [taxonomy_img, city_img, clusters_img]\n",
    "\n",
    "    # Auto panel size (3 images, equal margins)\n",
    "    margin, y = 40, 100\n",
    "    panel_width  = len(images) * thumb_size[0] + (len(images) + 1) * margin\n",
    "    panel_height = thumb_size[1] + 200\n",
    "    panel = Image.new(\"RGB\", (panel_width, panel_height), \"white\")\n",
    "    draw = ImageDraw.Draw(panel)\n",
    "\n",
    "    # Paste images\n",
    "    for i, img in enumerate(images):\n",
    "        x = margin + i * (thumb_size[0] + margin)\n",
    "        panel.paste(img, (x, y))\n",
    "\n",
    "    # Title: name + taxonomy + coordinates + type + radius\n",
    "    coords = f\"({city['coordinates'][0]:.4f}, {city['coordinates'][1]:.4f})\"\n",
    "    title_text = f\"{city['name']} ‚Äî {city['taxonomy']} ‚Äî {coords} - type={city['network']}, r={city['distance']} m\"\n",
    "    tw = draw.textlength(title_text, font=title_font) if hasattr(draw, \"textlength\") else title_font.getsize(title_text)[0]\n",
    "    draw.text(((panel_width - tw) // 2, 20), title_text, font=title_font, fill=\"black\")\n",
    "\n",
    "    slides.append(panel)\n",
    "    print(f\"‚úÖ Panel created: {city['name']}\")\n",
    "\n",
    "# Export to PDF (all slides)\n",
    "comparison_images_rgb = [img.convert(\"RGB\") for img in slides]\n",
    "comparison_images_rgb[0].save(pdf_file, save_all=True, append_images=comparison_images_rgb[1:], format=\"PDF\")\n",
    "print(f\"üìÑ Exported to: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a554be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Land",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
