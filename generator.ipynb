{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635387aa",
   "metadata": {},
   "source": [
    "# --- Settings ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cities loaded\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import os, time, json, csv, multiprocessing as mp\n",
    "from time import perf_counter\n",
    "\n",
    "# Third-party\n",
    "import numpy as np, pandas as pd, networkx as nx, osmnx as ox, umap\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from hdbscan import HDBSCAN\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"umap\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib.externals.loky\")\n",
    "\n",
    "# Fast BLAS on Apple Silicon\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# OSMnx settings\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "# Files & directories\n",
    "pdf_file = \"comparison.pdf\"\n",
    "map_dir, tax_dir, emb_dir, gra_dir, clu_dir = \"maps\", \"taxonomy\", \"embeddings\", \"graphs\", \"clusters\"\n",
    "for d in (map_dir, tax_dir, emb_dir, gra_dir, clu_dir):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---- GSD-inspired earthy mapping palette ----\n",
    "NEUTRAL = \"#CCCCCC\"\n",
    "PALETTE = [\n",
    "    \"#A4653E\",  # brighter terracotta\n",
    "    \"#D9985E\",  # lighter ochre\n",
    "    \"#88B28B\",  # fresher sage green\n",
    "    \"#69A8B2\",  # clearer teal\n",
    "    \"#B2879C\",  # livelier mauve\n",
    "    \"#6A717A\",  # lighter slate gray\n",
    "    \"#E0D3B0\",  # brighter pale stone\n",
    "    \"#9C7384\",  # stronger plum\n",
    "]\n",
    "\n",
    "city_data = [\n",
    "    {\"name\": \"Rome\", \"country\": \"ITA\",\n",
    "        \"coordinates\": (41.894096, 12.485609), \"distance\": 12000, \"network\": \"drive\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Radial_Implosion\"},\n",
    "    {\"name\": \"Vatican_City\", \"country\": \"VAT\",\n",
    "        \"coordinates\": (41.902257, 12.457421), \"distance\": 200, \"network\": \"all\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Elliptical_Implosion\"},\n",
    "    {\"name\": \"Fez\", \"country\": \"MAR\",\n",
    "        \"coordinates\": (34.065, -4.973), \"distance\": 800, \"network\": \"all\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Organic_Rhizome\"},\n",
    "    {\"name\": \"Moscow\", \"country\": \"RUS\",\n",
    "        \"coordinates\": (55.7558, 37.6176), \"distance\": 60000, \"network\": \"drive\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Centralized_Burst\"},\n",
    "    {\"name\": \"Medellin\", \"country\": \"COL\",\n",
    "        \"coordinates\": (6.2518, -75.5836), \"distance\": 15000, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Arc_Diagram\"},\n",
    "    {\"name\": \"Palmanova\", \"country\": \"ITA\",\n",
    "        \"coordinates\": (45.9061, 13.3095), \"distance\": 1500, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Radial_Convergence\"},\n",
    "    {\"name\": \"Dubai\", \"country\": \"ARE\",\n",
    "        \"coordinates\": (25.056530, 55.207939), \"distance\": 1000, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Segmented_Radial_Convergence\"},\n",
    "    {\"name\": \"Canberra\", \"country\": \"AUS\",\n",
    "        \"coordinates\": (-35.308188, 149.124441), \"distance\": 3200, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Centralized_Ring\"},\n",
    "    {\"name\": \"Los_Angeles\", \"country\": \"USA\",\n",
    "        \"coordinates\": (34.029315, -118.214444), \"distance\": 800, \"network\": \"drive\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Flow_Chart\"},\n",
    "    {\"name\": \"Randstad\", \"country\": \"NLD\",\n",
    "        \"coordinates\": (52.1, 4.6), \"distance\": 40000, \"network\": \"drive\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Area_Grouping\"},\n",
    "    {\"name\": \"Greater_Cairo\", \"country\": \"EGY\",\n",
    "        \"coordinates\": (30.0444, 31.2357), \"distance\": 50000, \"network\": \"drive\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Circular_Ties\"},\n",
    "    {\"name\": \"Amsterdam\", \"country\": \"NLD\",\n",
    "        \"coordinates\": (52.371, 4.90), \"distance\": 2000, \"network\": \"all\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Ramification\"}\n",
    "]\n",
    "\n",
    "# --- Choose which cities to process ---\n",
    "TARGET_CITIES = None   # None = process all cities\n",
    "# TARGET_CITIES = [\"Amsterdam\", \"Canberra\"]  # uncomment to process only Amsterdam\n",
    "\n",
    "print(f\"{len(city_data)} cities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc3cf",
   "metadata": {},
   "source": [
    "# --- Graphs ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e2d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rome (drive, r=12000m) â€” saved in 43.3s\n",
      "âœ… Vatican_City (all, r=200m) â€” saved in 0.9s\n",
      "âœ… Fez (all, r=800m) â€” saved in 2.0s\n",
      "âœ… Moscow (drive, r=60000m) â€” saved in 128.6s\n",
      "âœ… Medellin (all, r=15000m) â€” saved in 62.9s\n",
      "âœ… Palmanova (all, r=1500m) â€” saved in 0.9s\n",
      "âœ… Dubai (all, r=1000m) â€” saved in 2.3s\n",
      "âœ… Canberra (all, r=3200m) â€” saved in 12.8s\n",
      "âœ… Los_Angeles (drive, r=800m) â€” saved in 0.4s\n",
      "âœ… Randstad (drive, r=40000m) â€” saved in 189.8s\n",
      "âœ… Greater_Cairo (drive, r=50000m) â€” saved in 332.0s\n",
      "âœ… Amsterdam (all, r=2000m) â€” saved in 8.1s\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "    \n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "\n",
    "    # if os.path.exists(gpath):\n",
    "    #     print(f\"ğŸ—‚ï¸ {city['name']} skipped (already exists)\")\n",
    "    #     continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    G = ox.graph_from_point(\n",
    "        city['coordinates'],\n",
    "        dist=city['distance'],\n",
    "        network_type=city['network'],\n",
    "        simplify=True,\n",
    "        retain_all=False\n",
    "    )\n",
    "    ox.save_graphml(G, gpath)\n",
    "    dt = perf_counter() - t0\n",
    "    print(f\"âœ… {city['name']} ({city['network']}, r={city['distance']}m) â€” saved in {dt:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65636f52",
   "metadata": {},
   "source": [
    "# --- Node2Vec ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6c6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Saved Rome (32269 nodes) in 32.5s\n",
      "   âœ… Saved Vatican_City (149 nodes) in 0.2s\n",
      "   âœ… Saved Fez (1506 nodes) in 1.1s\n",
      "   âœ… Saved Moscow (107428 nodes) in 102.7s\n",
      "   âœ… Saved Medellin (69842 nodes) in 72.7s\n",
      "   âœ… Saved Palmanova (678 nodes) in 0.8s\n",
      "   âœ… Saved Dubai (1763 nodes) in 1.3s\n",
      "   âœ… Saved Canberra (14523 nodes) in 13.1s\n",
      "   âœ… Saved Los_Angeles (184 nodes) in 0.2s\n",
      "   âœ… Saved Randstad (183497 nodes) in 191.7s\n",
      "   âœ… Saved Greater_Cairo (466594 nodes) in 584.5s\n",
      "   âœ… Saved Amsterdam (10087 nodes) in 13.2s\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    npz_path = os.path.join(emb_dir, f\"{city['name']}.npz\")\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # largest connected component â†’ a single â€œstory worldâ€ for the walks\n",
    "    H = nx.Graph(ox.load_graphml(os.path.join(gra_dir, f\"{city['name']}.graphml\")))\n",
    "    H = H.subgraph(max(nx.connected_components(H), key=len)).copy()\n",
    "    node_list = list(H.nodes())\n",
    "\n",
    "    # Node2Vec sampler (Grover & Leskovec): biased 2nd-order random walks\n",
    "    n2v = Node2Vec(\n",
    "        H,\n",
    "        dimensions=32,          # embedding dimensionality (the space the walks learn)\n",
    "        walk_length=15,         # T: length of each 2nd-order walk\n",
    "        num_walks=8,            # Î³: walks launched per node (more = smoother estimates)\n",
    "        p=1.0,                  # return parameter: >1 discourages immediate backtracking; <1 encourages it\n",
    "        q=0.5,                  # in/out parameter: <1 â†’ BFS/homophily (stay local); >1 â†’ DFS/structural roles\n",
    "        workers=max(1, mp.cpu_count()-1),  # parallel samplers\n",
    "        seed=42,                # reproducible walk corpus\n",
    "        quiet=True              # hush the sampler\n",
    "    )\n",
    "\n",
    "    # Skip-gram optimizer on the walk corpus (word2vec on nodes)\n",
    "    model = n2v.fit(\n",
    "        window=5,               # context window (how far co-occurrence is trusted)\n",
    "        min_count=1,            # keep all nodes in the vocabulary\n",
    "        batch_words=128         # SGD batch size\n",
    "    )\n",
    "\n",
    "    # embeddings aligned to node_list order\n",
    "    X = np.array([model.wv[str(n)] for n in node_list])\n",
    "\n",
    "    np.savez_compressed(npz_path, X=X)\n",
    "    with open(ids_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(map(str, node_list)))\n",
    "\n",
    "    print(f\"   âœ… Saved {city['name']} ({len(node_list)} nodes) in {perf_counter()-t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f0cc4",
   "metadata": {},
   "source": [
    "# --- UMAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef23608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ï¸ Rome | PCA 0.0s | UMAP 17.6s | saved embeddings/Rome.npy\n",
      "ğŸ™ï¸ Vatican_City | PCA 0.0s | UMAP 2.0s | saved embeddings/Vatican_City.npy\n",
      "ğŸ™ï¸ Fez | PCA 0.0s | UMAP 1.1s | saved embeddings/Fez.npy\n",
      "ğŸ™ï¸ Moscow | PCA 0.1s | UMAP 33.1s | saved embeddings/Moscow.npy\n",
      "ğŸ™ï¸ Medellin | PCA 0.0s | UMAP 20.7s | saved embeddings/Medellin.npy\n",
      "ğŸ™ï¸ Palmanova | PCA 0.0s | UMAP 0.3s | saved embeddings/Palmanova.npy\n",
      "ğŸ™ï¸ Dubai | PCA 0.0s | UMAP 1.4s | saved embeddings/Dubai.npy\n",
      "ğŸ™ï¸ Canberra | PCA 0.0s | UMAP 4.1s | saved embeddings/Canberra.npy\n",
      "ğŸ™ï¸ Los_Angeles | PCA 0.0s | UMAP 0.0s | saved embeddings/Los_Angeles.npy\n",
      "ğŸ™ï¸ Randstad | PCA 0.1s | UMAP 60.2s | saved embeddings/Randstad.npy\n",
      "ğŸ™ï¸ Greater_Cairo | PCA 0.3s | UMAP 192.3s | saved embeddings/Greater_Cairo.npy\n",
      "ğŸ™ï¸ Amsterdam | PCA 0.0s | UMAP 3.1s | saved embeddings/Amsterdam.npy\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES is not None and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    X = np.load(os.path.join(emb_dir, f\"{city['name']}.npz\"))[\"X\"].astype(\"float32\")\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "\n",
    "    # Normalize + PCA\n",
    "    X_red = PCA(n_components=16, random_state=0).fit_transform(normalize(X, norm=\"l2\"))\n",
    "    t_pca = perf_counter()\n",
    "\n",
    "    # UMAP\n",
    "    embed = umap.UMAP(\n",
    "        n_neighbors=8,     # 8 words nicely to keep the global structure (5 leaves holes in the structure of the city)\n",
    "        min_dist=0.20,      # was 0.20; gives a nice balance between local and global structure\n",
    "        metric=\"euclidean\", # fine on normalized/PCA data\n",
    "        random_state=42,\n",
    "        n_epochs=150,\n",
    "        low_memory=True,\n",
    "    ).fit_transform(X_red)\n",
    "\n",
    "    np.save(umap_path, embed)\n",
    "    print(f\"ğŸ™ï¸ {city['name']} | PCA {t_pca-t0:.1f}s | UMAP {perf_counter()-t_pca:.1f}s | saved {umap_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eb360",
   "metadata": {},
   "source": [
    "# --- HDBSCAN ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3552a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ï¸ Rome | HDBSCAN 2.2s | clusters 7 | noise 11376/32269 (35.3%) â†’ clusters/Rome.csv\n",
      "ğŸ™ï¸ Vatican_City | HDBSCAN 0.1s | clusters 3 | noise 42/149 (28.2%) â†’ clusters/Vatican_City.csv\n",
      "ğŸ™ï¸ Fez | HDBSCAN 0.1s | clusters 4 | noise 578/1506 (38.4%) â†’ clusters/Fez.csv\n",
      "ğŸ™ï¸ Moscow | HDBSCAN 2.0s | clusters 5 | noise 77533/107428 (72.2%) â†’ clusters/Moscow.csv\n",
      "ğŸ™ï¸ Medellin | HDBSCAN 1.3s | clusters 5 | noise 44829/69842 (64.2%) â†’ clusters/Medellin.csv\n",
      "ğŸ™ï¸ Palmanova | HDBSCAN 0.1s | clusters 3 | noise 91/678 (13.4%) â†’ clusters/Palmanova.csv\n",
      "ğŸ™ï¸ Dubai | HDBSCAN 0.1s | clusters 3 | noise 342/1763 (19.4%) â†’ clusters/Dubai.csv\n",
      "ğŸ™ï¸ Canberra | HDBSCAN 0.3s | clusters 7 | noise 3553/14523 (24.5%) â†’ clusters/Canberra.csv\n",
      "ğŸ™ï¸ Los_Angeles | HDBSCAN 0.1s | clusters 3 | noise 10/184 (5.4%) â†’ clusters/Los_Angeles.csv\n",
      "ğŸ™ï¸ Randstad | HDBSCAN 3.6s | clusters 0 | noise 183497/183497 (100.0%) â†’ clusters/Randstad.csv\n",
      "ğŸ™ï¸ Greater_Cairo | HDBSCAN 11.3s | clusters 2 | noise 309779/466594 (66.4%) â†’ clusters/Greater_Cairo.csv\n",
      "ğŸ™ï¸ Amsterdam | HDBSCAN 0.2s | clusters 5 | noise 3840/10087 (38.1%) â†’ clusters/Amsterdam.csv\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load UMAP embedding\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "    embed = np.load(umap_path)\n",
    "\n",
    "    # Load node ids; fallback to sequential ids if file is missing\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "    with open(ids_path) as f:\n",
    "        node_list = [line.strip() for line in f]\n",
    "\n",
    "    # Sanity check: rows must match ids count\n",
    "    assert embed.shape[0] == len(node_list), (\n",
    "        f\"Mismatch: {embed.shape[0]} embeddings vs {len(node_list)} ids for {city['name']}\"\n",
    "    )\n",
    "\n",
    "    # HDBSCAN on UMAP space (2D)\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=max(10, int(len(node_list) ** 0.70)),\n",
    "        min_samples=3,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"leaf\",\n",
    "        cluster_selection_epsilon=0.06,\n",
    "        prediction_data=False,\n",
    "        approx_min_span_tree=True,\n",
    "        gen_min_span_tree=False,\n",
    "        algorithm=\"best\",\n",
    "        core_dist_n_jobs=mp.cpu_count(),\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embed)  # -1 = noise\n",
    "\n",
    "    # Map cluster â†’ color using the GLOBAL PALETTE (stable order)\n",
    "    uniq = sorted(set(labels) - {-1})\n",
    "    label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "    point_colors = [label2color.get(lbl, NEUTRAL) for lbl in labels]\n",
    "\n",
    "    # Save colored embedding (for visual checks)\n",
    "    out_jpg = os.path.join(clu_dir, f\"{city['name']}.jpg\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embed[:, 0], embed[:, 1], s=1.5, c=point_colors, alpha=0.9, edgecolor='none')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_jpg, dpi=600, bbox_inches=\"tight\", format=\"jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    # Persist exact colors per node\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"node_id\", \"cluster\", \"color_hex\"])\n",
    "        for nid, lbl, col in zip(node_list, labels, point_colors):\n",
    "            w.writerow([nid, int(lbl), col])\n",
    "\n",
    "    noise = int((labels == -1).sum())\n",
    "    print(f\"ğŸ™ï¸ {city['name']} | HDBSCAN {perf_counter()-t0:.1f}s | clusters {len(uniq)} | noise {noise}/{len(node_list)} ({noise/len(node_list):.1%}) â†’ {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918d23d",
   "metadata": {},
   "source": [
    "# --- Maps ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76365b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ºï¸ Rome | map 9.7s â†’ maps/Rome.png\n",
      "ğŸ—ºï¸ Vatican_City | map 0.2s â†’ maps/Vatican_City.png\n",
      "ğŸ—ºï¸ Fez | map 1.1s â†’ maps/Fez.png\n",
      "ğŸ—ºï¸ Moscow | map 33.0s â†’ maps/Moscow.png\n",
      "ğŸ—ºï¸ Medellin | map 21.6s â†’ maps/Medellin.png\n",
      "ğŸ—ºï¸ Palmanova | map 0.4s â†’ maps/Palmanova.png\n",
      "ğŸ—ºï¸ Dubai | map 0.6s â†’ maps/Dubai.png\n",
      "ğŸ—ºï¸ Canberra | map 5.7s â†’ maps/Canberra.png\n",
      "ğŸ—ºï¸ Los_Angeles | map 0.3s â†’ maps/Los_Angeles.png\n",
      "ğŸ—ºï¸ Randstad | map 54.5s â†’ maps/Randstad.png\n",
      "ğŸ—ºï¸ Greater_Cairo | map 173.2s â†’ maps/Greater_Cairo.png\n",
      "ğŸ—ºï¸ Amsterdam | map 5.8s â†’ maps/Amsterdam.png\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load graph\n",
    "    G = ox.load_graphml(os.path.join(gra_dir, f\"{city['name']}.graphml\"))\n",
    "\n",
    "    # Load cluster labels and the exact colors chosen earlier\n",
    "    node_cluster, node_color = {}, {}\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            nid = str(row[\"node_id\"])\n",
    "            node_cluster[nid] = int(row[\"cluster\"])\n",
    "            node_color[nid]   = row.get(\"color_hex\") or NEUTRAL\n",
    "\n",
    "    # Project and color edges: use a cluster color only when both endpoints share the same cluster; else NEUTRAL\n",
    "    G_proj = ox.project_graph(G)\n",
    "    edge_colors = [\n",
    "        (node_color.get(str(u), NEUTRAL)\n",
    "         if (node_cluster.get(str(u)) == node_cluster.get(str(v)) and\n",
    "             node_cluster.get(str(u), -1) != -1)\n",
    "         else NEUTRAL)\n",
    "        for u, v, k in G_proj.edges(keys=True)\n",
    "    ]\n",
    "\n",
    "    out_png = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    fig, ax = ox.plot_graph(\n",
    "        G_proj,\n",
    "        bgcolor=\"white\",\n",
    "        node_size=0,\n",
    "        edge_color=edge_colors,\n",
    "        edge_linewidth=0.4,\n",
    "        show=False,\n",
    "        save=True,\n",
    "        filepath=out_png,\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"ğŸ—ºï¸ {city['name']} | map {perf_counter()-t0:.1f}s â†’ {out_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9685",
   "metadata": {},
   "source": [
    "# --- Panels ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Exported to: comparison.pdf\n"
     ]
    }
   ],
   "source": [
    "# Layout params\n",
    "thumb_size = (1500, 1500)\n",
    "FONT_SIZE  = 40                 # one font size for everything\n",
    "margin     = 40\n",
    "title_y    = 20                  # top padding for the title\n",
    "\n",
    "# Try a few common fonts; fall back to PIL default if none found\n",
    "font = None\n",
    "for fp in [\"arial.ttf\", \"Arial.ttf\", \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
    "           \"/System/Library/Fonts/Supplemental/Arial Unicode.ttf\",\n",
    "           \"/Library/Fonts/Arial.ttf\", \"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\"]:\n",
    "    try:\n",
    "        font = ImageFont.truetype(fp, FONT_SIZE)\n",
    "        break\n",
    "    except Exception:\n",
    "        continue\n",
    "if font is None:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "def text_width(draw, text, font):\n",
    "    if hasattr(draw, \"textlength\"):\n",
    "        return draw.textlength(text, font=font)\n",
    "    # Fallback: use bbox width\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    return bbox[2] - bbox[0]\n",
    "\n",
    "slides = []\n",
    "\n",
    "for city in city_data:\n",
    "    city_path     = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    clusters_path = os.path.join(clu_dir, f\"{city['name']}.jpg\")\n",
    "\n",
    "    city_img     = Image.open(city_path).convert(\"RGB\").resize(thumb_size, Image.LANCZOS)\n",
    "    clusters_img = Image.open(clusters_path).convert(\"RGB\").resize(thumb_size, Image.LANCZOS)\n",
    "\n",
    "    images = [city_img, clusters_img]\n",
    "\n",
    "    # Panel size\n",
    "    panel_width  = len(images) * thumb_size[0] + (len(images) + 1) * margin\n",
    "    panel_height = thumb_size[1] + FONT_SIZE + 120  # room for big title\n",
    "    panel = Image.new(\"RGB\", (panel_width, panel_height), \"white\")\n",
    "    draw = ImageDraw.Draw(panel)\n",
    "\n",
    "    # Paste images\n",
    "    y = title_y + FONT_SIZE + 40\n",
    "    for i, img in enumerate(images):\n",
    "        x = margin + i * (thumb_size[0] + margin)\n",
    "        panel.paste(img, (x, y))\n",
    "\n",
    "    # Title: name + taxonomy + coordinates + type + radius\n",
    "    coords = f\"({city['coordinates'][0]:.4f}, {city['coordinates'][1]:.4f})\"\n",
    "    title_text = f\"{city['name']} â€” {city['taxonomy']} â€” {coords}  â€¢  type={city['network']}, r={city['distance']} m\"\n",
    "    tw = text_width(draw, title_text, font)\n",
    "    draw.text(((panel_width - tw) // 2, title_y), title_text, font=font, fill=\"black\")\n",
    "\n",
    "    slides.append(panel)\n",
    "\n",
    "# Export to PDF (all slides)\n",
    "comparison_images_rgb = [img.convert(\"RGB\") for img in slides]\n",
    "comparison_images_rgb[0].save(pdf_file, save_all=True, append_images=comparison_images_rgb[1:], format=\"PDF\")\n",
    "print(f\"ğŸ“„ Exported to: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a554be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Land",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
