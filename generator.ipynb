{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635387aa",
   "metadata": {},
   "source": [
    "# --- Settings ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "faefc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cities loaded\n"
     ]
    }
   ],
   "source": [
    "# ---- Imports ----\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import umap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"umap\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib.externals.loky\")\n",
    "\n",
    "# Fast BLAS on Apple Silicon\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# OSMnx settings\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "# Layout params\n",
    "thumb_size = (600, 600)\n",
    "font_size, title_font_size = 20, 26\n",
    "panel_width = 2 * thumb_size[0] + 3 * 40\n",
    "panel_height = thumb_size[1] + 3 * font_size + 80\n",
    "\n",
    "# Fonts\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    title_font = ImageFont.truetype(\"arial.ttf\", title_font_size)\n",
    "except Exception:\n",
    "    font = ImageFont.load_default()\n",
    "    title_font = ImageFont.load_default()\n",
    "\n",
    "# Files & directories\n",
    "pdf_file = \"comparison.pdf\"\n",
    "map_dir, tax_dir, emb_dir, gra_dir = \"maps\", \"taxonomy\", \"embeddings\", \"graphs\"\n",
    "for d in (map_dir, tax_dir, emb_dir, gra_dir):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---- Colors ----\n",
    "NEUTRAL = \"#CCCCCC\"\n",
    "PALETTE = [\n",
    "    \"#2E1F3C\",  # balanced deep violet\n",
    "    \"#A13F82\",  # balanced magenta\n",
    "    \"#6B3F9B\",  # balanced purple\n",
    "    \"#1D6FAF\",  # balanced blue\n",
    "    \"#3F9FD1\",  # balanced light blue\n",
    "    \"#2E9C90\",  # balanced teal\n",
    "    \"#D8922F\",  # balanced amber\n",
    "    \"#C23B3B\",  # balanced red\n",
    "]\n",
    "\n",
    "# Ensure consistent HEX format\n",
    "PALETTE = [mpl.colors.to_hex(c) for c in PALETTE]\n",
    "\n",
    "city_data = [\n",
    "    {\"name\":\"Rome\",\"country\":\"ITA\",\"coordinates\":(41.894096,12.485609),\"distance\":12000,\"group\":\"Archetypal\",\"taxonomy\":\"Radial_Implosion\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Vatican_City\",\"country\":\"VAT\",\"coordinates\":(41.902257,12.457421),\"distance\":200,\"group\":\"Archetypal\",\"taxonomy\":\"Elliptical_Implosion\",\"network\":\"all\"},\n",
    "    {\"name\":\"Fez\",\"country\":\"MAR\",\"coordinates\":(34.065,-4.973),\"distance\":800,\"group\":\"Archetypal\",\"taxonomy\":\"Organic_Rhizome\",\"network\":\"all\"},\n",
    "    {\"name\":\"Moscow\",\"country\":\"RUS\",\"coordinates\":(55.7558,37.6176),\"distance\":60000,\"group\":\"Archetypal\",\"taxonomy\":\"Centralized_Burst\",\"network\":\"drive\"},\n",
    "    \n",
    "    {\"name\":\"Medellin\",\"country\":\"COL\",\"coordinates\":(6.2518,-75.5836),\"distance\":15000,\"group\":\"Geometrical\",\"taxonomy\":\"Arc_Diagram\",\"network\":\"all\"},\n",
    "    {\"name\":\"Palmanova\",\"country\":\"ITA\",\"coordinates\":(45.9061,13.3095),\"distance\":1500,\"group\":\"Geometrical\",\"taxonomy\":\"Radial_Convergence\",\"network\":\"all\"},\n",
    "    {\"name\":\"Dubai\",\"country\":\"ARE\",\"coordinates\":(25.056530,55.207939),\"distance\":1000,\"group\":\"Geometrical\",\"taxonomy\":\"Segmented_Radial_Convergence\",\"network\":\"all\"},\n",
    "    {\"name\":\"Canberra\",\"country\":\"AUS\",\"coordinates\":(-35.308188,149.124441),\"distance\":3200,\"group\":\"Geometrical\",\"taxonomy\":\"Centralized_Ring\",\"network\":\"all\"},\n",
    "    \n",
    "    {\"name\":\"Los_Angeles\",\"country\":\"USA\",\"coordinates\":(34.029315,-118.214444),\"distance\":800,\"group\":\"Relational\",\"taxonomy\":\"Flow_Chart\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Randstad\",\"country\":\"NLD\",\"coordinates\":(52.1,4.6),\"distance\":40000,\"group\":\"Relational\",\"taxonomy\":\"Area_Grouping\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Greater_Cairo\",\"country\":\"EGY\",\"coordinates\":(30.0444,31.2357),\"distance\":50000,\"group\":\"Relational\",\"taxonomy\":\"Circular_Ties\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Amsterdam\",\"country\":\"NLD\",\"coordinates\":(52.371,4.90),\"distance\":2000,\"group\":\"Relational\",\"taxonomy\":\"Ramification\",\"network\":\"all\"},\n",
    "]\n",
    "\n",
    "print(f\"{len(city_data)} cities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc3cf",
   "metadata": {},
   "source": [
    "# --- Graphs ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e2d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‚ï¸  Graph exists â€” skipped: Rome\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Vatican_City\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Fez\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Moscow\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Medellin\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Palmanova\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Dubai\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Canberra\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Los_Angeles\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Randstad\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Greater_Cairo\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Amsterdam\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "\n",
    "    if os.path.exists(gpath):\n",
    "        print(f\"ðŸ—‚ï¸  Graph exists â€” skipped: {city['name']}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸ”„ {city['name']} ({city['network']}, r={city['distance']}m)â€¦\")\n",
    "        G = ox.graph_from_point(city['coordinates'], dist=city['distance'], network_type=city['network'], simplify=True, retain_all=False)\n",
    "        ox.save_graphml(G, gpath)\n",
    "        print(f\"âœ… Saved: {gpath}\")\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed for {city['name']}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65636f52",
   "metadata": {},
   "source": [
    "# --- Node2Vec ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e6c6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ™ï¸  Node2Vec: Rome\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m node_list = \u001b[38;5;28mlist\u001b[39m(H.nodes())  \u001b[38;5;66;03m# preserve order!\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Node2Vec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m n2v = \u001b[43mNode2Vec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN2V_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN2V_WALKLEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN2V_NUMWALKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m model = n2v.fit(window=N2V_WINDOW, min_count=N2V_MINCOUNT, batch_words=N2V_BATCHWORDS)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Embedding matrix aligned with node_list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/Land/lib/python3.11/site-packages/node2vec/node2vec.py:74\u001b[39m, in \u001b[36mNode2Vec.__init__\u001b[39m\u001b[34m(self, graph, dimensions, walk_length, num_walks, p, q, weight_key, workers, sampling_strategy, quiet, temp_folder, seed)\u001b[39m\n\u001b[32m     71\u001b[39m     np.random.seed(seed)\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m._precompute_probabilities()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28mself\u001b[39m.walks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_walks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/Land/lib/python3.11/site-packages/node2vec/node2vec.py:159\u001b[39m, in \u001b[36mNode2Vec._generate_walks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# Split num_walks for each worker\u001b[39;00m\n\u001b[32m    157\u001b[39m num_walks_lists = np.array_split(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_walks), \u001b[38;5;28mself\u001b[39m.workers)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m walk_results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemp_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel_generate_walks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43md_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_walks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mNUM_WALKS_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mWALK_LENGTH_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mNEIGHBORS_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mPROBABILITIES_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mFIRST_TRAVEL_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_walks\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_walks_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m walks = flatten(walk_results)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m walks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/Land/lib/python3.11/site-packages/joblib/parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/Land/lib/python3.11/site-packages/joblib/parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/Land/lib/python3.11/site-packages/joblib/parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Precompute Node2Vec for each city and save to disk (fast later runs)\n",
    "# Files written per city:\n",
    "#   emb_dir/{City}.npz    -> compressed array \"X\" of shape (n_nodes, N2V_DIM)\n",
    "#   emb_dir/{City}.ids    -> one node id per line (order matters)\n",
    "\n",
    "N2V_DIM, N2V_WALKLEN, N2V_NUMWALKS = 32, 15, 8\n",
    "N2V_WINDOW, N2V_MINCOUNT, N2V_BATCHWORDS = 5, 1, 128\n",
    "\n",
    "for city in city_data:\n",
    "    print(f\"ðŸ™ï¸  Node2Vec: {city['name']}\")\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    G = ox.load_graphml(gpath)\n",
    "\n",
    "    # largest connected component for stable embeddings\n",
    "    H = nx.Graph(G).subgraph(max(nx.connected_components(nx.Graph(G)), key=len)).copy()\n",
    "    node_list = list(H.nodes())  # preserve order!\n",
    "\n",
    "    # Node2Vec\n",
    "    n2v = Node2Vec(\n",
    "        H, dimensions=N2V_DIM, walk_length=N2V_WALKLEN, num_walks=N2V_NUMWALKS,\n",
    "        p=1, q=1, workers=max(1, mp.cpu_count()-1), seed=42, quiet=True\n",
    "    )\n",
    "    model = n2v.fit(window=N2V_WINDOW, min_count=N2V_MINCOUNT, batch_words=N2V_BATCHWORDS)\n",
    "\n",
    "    # Embedding matrix aligned with node_list\n",
    "    X = np.array([model.wv[str(n)] for n in node_list])\n",
    "\n",
    "    # Save embeddings\n",
    "    np.savez_compressed(os.path.join(emb_dir, f\"{city['name']}.npz\"), X=X)\n",
    "\n",
    "    # Save node ids\n",
    "    with open(os.path.join(emb_dir, f\"{city['name']}.ids\"), \"w\") as f:\n",
    "        for n in node_list:\n",
    "            f.write(f\"{n}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f0cc4",
   "metadata": {},
   "source": [
    "# --- UMAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ef23608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ™ï¸  Processing Amsterdam\n",
      "   - clusters: 87, noise: 3574/10087 (35.4%)\n",
      "   - Wrote: embeddings/Amsterdam.jpg\n",
      "   - Cluster file: embeddings/Amsterdam.csv\n"
     ]
    }
   ],
   "source": [
    "# UMAP (for visualization)\n",
    "UMAP_NEIGHBORS, UMAP_MINDIST, UMAP_METRIC, UMAP_SEED = 15, 0.1, \"cosine\", 42\n",
    "\n",
    "for city in city_data:\n",
    "    \n",
    "    if city['name'] != \"Amsterdam\":\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nðŸ™ï¸  Processing {city['name']}\")\n",
    "\n",
    "    # Load saved Node2Vec\n",
    "    X = np.load(os.path.join(emb_dir, f\"{city['name']}.npz\"))[\"X\"]\n",
    "    with open(os.path.join(emb_dir, f\"{city['name']}.ids\")) as f:\n",
    "        node_list = [line.strip() for line in f]\n",
    "\n",
    "    # UMAP for visualization (always the same for given X + seed)\n",
    "    embed = umap.UMAP(\n",
    "        n_neighbors=UMAP_NEIGHBORS, min_dist=UMAP_MINDIST,\n",
    "        metric=UMAP_METRIC, random_state=UMAP_SEED\n",
    "    ).fit_transform(X)\n",
    "\n",
    "    # Normalize for â€œcosine-likeâ€ geometry\n",
    "    X_norm = normalize(X, norm=\"l2\")\n",
    "    n = len(node_list)\n",
    "\n",
    "    # --- HDBSCAN clustering in Node2Vec space ---\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=max(10, int(n ** 0.48)),  # moderate exponent â†’ bigger than 0.40, smaller than 0.55\n",
    "        min_samples=3,                             # a bit stricter than 2, but not as strict as 5\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"leaf\",           # still keeps some detail\n",
    "        cluster_selection_epsilon=0.03,            # merges a bit more, but not too much\n",
    "        prediction_data=False\n",
    "    )\n",
    "    labels = clusterer.fit_predict(X_norm)      # -1 = noise\n",
    "\n",
    "    # Build palette from global PALETTE (noise gets NEUTRAL)\n",
    "    uniq = sorted(set(labels) - {-1})\n",
    "    label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "    point_colors = [label2color.get(lbl, NEUTRAL) for lbl in labels]\n",
    "\n",
    "    # Save embedding image\n",
    "    out_jpg = os.path.join(emb_dir, f\"{city['name']}.jpg\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embed[:, 0], embed[:, 1], s=1, c=point_colors, alpha=1, edgecolor='none')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_jpg, dpi=600, bbox_inches=\"tight\", format=\"jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save node â†’ cluster â†’ color\n",
    "    csv_path = os.path.join(emb_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"node_id\", \"cluster\", \"color_hex\"])\n",
    "        for nid, lbl, col in zip(node_list, labels, point_colors):\n",
    "            w.writerow([nid, int(lbl), col])\n",
    "\n",
    "    noise = int((labels == -1).sum())\n",
    "    print(f\"   - clusters: {n_clusters}, noise: {noise}/{n} ({noise/n:.1%})\")\n",
    "    print(f\"   - Wrote: {out_jpg}\")\n",
    "    print(f\"   - Cluster file: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918d23d",
   "metadata": {},
   "source": [
    "# --- Maps ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e76365b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€“ Generating map for Amsterdamâ€¦\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    \n",
    "    if city['name'] != \"Amsterdam\":\n",
    "        continue\n",
    "\n",
    "    print(f\"â€“ Generating map for {city['name']}â€¦\")\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    G = ox.load_graphml(gpath)\n",
    "\n",
    "    # Load node -> cluster from CSV produced during embedding\n",
    "    csv_path = os.path.join(emb_dir, f\"{city['name']}.csv\")\n",
    "    node_cluster = {}\n",
    "    if os.path.exists(csv_path):\n",
    "        import csv\n",
    "        with open(csv_path, newline=\"\") as f:\n",
    "            r = csv.DictReader(f)\n",
    "            for row in r:\n",
    "                nid = str(row[\"node_id\"])\n",
    "                node_cluster[nid] = int(row[\"cluster\"])\n",
    "    else:\n",
    "        node_cluster = {}\n",
    "\n",
    "    # Build a stable color mapping from global PALETTE\n",
    "    # (ignore noise = -1, which will be NEUTRAL)\n",
    "    if node_cluster:\n",
    "        uniq = sorted({c for c in node_cluster.values() if c != -1})\n",
    "        label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "        node_color = {nid: label2color.get(lbl, NEUTRAL) if lbl != -1 else NEUTRAL\n",
    "                      for nid, lbl in node_cluster.items()}\n",
    "    else:\n",
    "        node_color = {}\n",
    "\n",
    "    # Project the SAME graph you will plot\n",
    "    G_proj = ox.project_graph(G)\n",
    "\n",
    "    # Build edge colors using both endpoints; color only if clusters match\n",
    "    edges_proj = list(G_proj.edges(keys=True))\n",
    "    if node_color:\n",
    "        edge_colors = []\n",
    "        for u, v, k in edges_proj:\n",
    "            u_id, v_id = str(u), str(v)\n",
    "            cu = node_cluster.get(u_id, None)\n",
    "            cv = node_cluster.get(v_id, None)\n",
    "            if cu is not None and cv is not None and cu == cv and cu != -1:\n",
    "                edge_colors.append(node_color.get(u_id, NEUTRAL))\n",
    "            else:\n",
    "                edge_colors.append(NEUTRAL)\n",
    "    else:\n",
    "        edge_colors = \"black\"\n",
    "\n",
    "    out_png = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    ox.plot_graph(\n",
    "        G_proj,\n",
    "        bgcolor=\"white\",\n",
    "        node_size=0,\n",
    "        edge_color=edge_colors,\n",
    "        edge_linewidth=0.3,\n",
    "        show=False,\n",
    "        save=True,\n",
    "        filepath=out_png,\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9685",
   "metadata": {},
   "source": [
    "# --- Panels ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "91e2a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Panel created: Rome\n",
      "âœ… Panel created: Vatican_City\n",
      "âœ… Panel created: Fez\n",
      "âœ… Panel created: Moscow\n",
      "âœ… Panel created: Medellin\n",
      "âœ… Panel created: Palmanova\n",
      "âœ… Panel created: Dubai\n",
      "âœ… Panel created: Canberra\n",
      "âœ… Panel created: Los_Angeles\n",
      "âœ… Panel created: Randstad\n",
      "âœ… Panel created: Greater_Cairo\n",
      "âœ… Panel created: Amsterdam\n",
      "ðŸ“„ Exported to: comparison.pdf\n"
     ]
    }
   ],
   "source": [
    "slides = []\n",
    "\n",
    "for city in city_data:\n",
    "    taxonomy_path = os.path.join(tax_dir, f\"{city['taxonomy']}.jpg\")\n",
    "    city_path     = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    embedding_path  = os.path.join(emb_dir, f\"{city['name']}.jpg\")\n",
    "\n",
    "    taxonomy_img = Image.open(taxonomy_path).convert(\"RGB\").resize(thumb_size)\n",
    "    city_img     = Image.open(city_path).convert(\"RGB\").resize(thumb_size)\n",
    "    embedding_img  = Image.open(embedding_path).convert(\"RGB\").resize(thumb_size)\n",
    "\n",
    "    images = [taxonomy_img, city_img, embedding_img]\n",
    "\n",
    "    # Auto panel size (3 images, equal margins)\n",
    "    margin, y = 40, 100\n",
    "    panel_width  = len(images) * thumb_size[0] + (len(images) + 1) * margin\n",
    "    panel_height = thumb_size[1] + 200\n",
    "    panel = Image.new(\"RGB\", (panel_width, panel_height), \"white\")\n",
    "    draw = ImageDraw.Draw(panel)\n",
    "\n",
    "    # Paste images\n",
    "    for i, img in enumerate(images):\n",
    "        x = margin + i * (thumb_size[0] + margin)\n",
    "        panel.paste(img, (x, y))\n",
    "\n",
    "    # Title: name + taxonomy + coordinates + type + radius\n",
    "    coords = f\"({city['coordinates'][0]:.4f}, {city['coordinates'][1]:.4f})\"\n",
    "    title_text = f\"{city['name']} â€” {city['taxonomy']} â€” {coords} - type={city['network']}, r={city['distance']} m\"\n",
    "    tw = draw.textlength(title_text, font=title_font) if hasattr(draw, \"textlength\") else title_font.getsize(title_text)[0]\n",
    "    draw.text(((panel_width - tw) // 2, 20), title_text, font=title_font, fill=\"black\")\n",
    "\n",
    "    slides.append(panel)\n",
    "    print(f\"âœ… Panel created: {city['name']}\")\n",
    "\n",
    "# Export to PDF (all slides)\n",
    "comparison_images_rgb = [img.convert(\"RGB\") for img in slides]\n",
    "comparison_images_rgb[0].save(pdf_file, save_all=True, append_images=comparison_images_rgb[1:], format=\"PDF\")\n",
    "print(f\"ðŸ“„ Exported to: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d543d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Land",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
