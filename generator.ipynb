{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635387aa",
   "metadata": {},
   "source": [
    "# --- Settings ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faefc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cities loaded\n"
     ]
    }
   ],
   "source": [
    "# ---- Imports ----\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import umap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"umap\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib.externals.loky\")\n",
    "\n",
    "# Fast BLAS on Apple Silicon\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# OSMnx settings\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "# Layout params\n",
    "thumb_size = (600, 600)\n",
    "font_size, title_font_size = 20, 26\n",
    "panel_width = 2 * thumb_size[0] + 3 * 40\n",
    "panel_height = thumb_size[1] + 3 * font_size + 80\n",
    "\n",
    "# Fonts\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    title_font = ImageFont.truetype(\"arial.ttf\", title_font_size)\n",
    "except Exception:\n",
    "    font = ImageFont.load_default()\n",
    "    title_font = ImageFont.load_default()\n",
    "\n",
    "# Files & directories\n",
    "pdf_file = \"comparison.pdf\"\n",
    "map_dir, tax_dir, emb_dir, gra_dir = \"maps\", \"taxonomy\", \"embeddings\", \"graphs\"\n",
    "for d in (map_dir, tax_dir, emb_dir, gra_dir):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---- Colors ----\n",
    "NEUTRAL = \"#CCCCCC\"\n",
    "PALETTE = [\n",
    "    \"#2E1F3C\",  # balanced deep violet\n",
    "    \"#A13F82\",  # balanced magenta\n",
    "    \"#6B3F9B\",  # balanced purple\n",
    "    \"#1D6FAF\",  # balanced blue\n",
    "    \"#3F9FD1\",  # balanced light blue\n",
    "    \"#2E9C90\",  # balanced teal\n",
    "    \"#D8922F\",  # balanced amber\n",
    "    \"#C23B3B\",  # balanced red\n",
    "]\n",
    "\n",
    "# Ensure consistent HEX format\n",
    "PALETTE = [mpl.colors.to_hex(c) for c in PALETTE]\n",
    "\n",
    "city_data = [\n",
    "    {\"name\":\"Rome\",\"country\":\"ITA\",\"coordinates\":(41.894096,12.485609),\"distance\":12000,\"group\":\"Archetypal\",\"taxonomy\":\"Radial_Implosion\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Vatican_City\",\"country\":\"VAT\",\"coordinates\":(41.902257,12.457421),\"distance\":200,\"group\":\"Archetypal\",\"taxonomy\":\"Elliptical_Implosion\",\"network\":\"all\"},\n",
    "    {\"name\":\"Fez\",\"country\":\"MAR\",\"coordinates\":(34.065,-4.973),\"distance\":800,\"group\":\"Archetypal\",\"taxonomy\":\"Organic_Rhizome\",\"network\":\"all\"},\n",
    "    {\"name\":\"Moscow\",\"country\":\"RUS\",\"coordinates\":(55.7558,37.6176),\"distance\":60000,\"group\":\"Archetypal\",\"taxonomy\":\"Centralized_Burst\",\"network\":\"drive\"},\n",
    "    \n",
    "    {\"name\":\"Medellin\",\"country\":\"COL\",\"coordinates\":(6.2518,-75.5836),\"distance\":15000,\"group\":\"Geometrical\",\"taxonomy\":\"Arc_Diagram\",\"network\":\"all\"},\n",
    "    {\"name\":\"Palmanova\",\"country\":\"ITA\",\"coordinates\":(45.9061,13.3095),\"distance\":1500,\"group\":\"Geometrical\",\"taxonomy\":\"Radial_Convergence\",\"network\":\"all\"},\n",
    "    {\"name\":\"Dubai\",\"country\":\"ARE\",\"coordinates\":(25.056530,55.207939),\"distance\":1000,\"group\":\"Geometrical\",\"taxonomy\":\"Segmented_Radial_Convergence\",\"network\":\"all\"},\n",
    "    {\"name\":\"Canberra\",\"country\":\"AUS\",\"coordinates\":(-35.308188,149.124441),\"distance\":3200,\"group\":\"Geometrical\",\"taxonomy\":\"Centralized_Ring\",\"network\":\"all\"},\n",
    "    \n",
    "    {\"name\":\"Los_Angeles\",\"country\":\"USA\",\"coordinates\":(34.029315,-118.214444),\"distance\":800,\"group\":\"Relational\",\"taxonomy\":\"Flow_Chart\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Randstad\",\"country\":\"NLD\",\"coordinates\":(52.1,4.6),\"distance\":40000,\"group\":\"Relational\",\"taxonomy\":\"Area_Grouping\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Greater_Cairo\",\"country\":\"EGY\",\"coordinates\":(30.0444,31.2357),\"distance\":50000,\"group\":\"Relational\",\"taxonomy\":\"Circular_Ties\",\"network\":\"drive\"},\n",
    "    {\"name\":\"Amsterdam\",\"country\":\"NLD\",\"coordinates\":(52.371,4.90),\"distance\":2000,\"group\":\"Relational\",\"taxonomy\":\"Ramification\",\"network\":\"all\"},\n",
    "]\n",
    "\n",
    "print(f\"{len(city_data)} cities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc3cf",
   "metadata": {},
   "source": [
    "# --- Graphs ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e2d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‚ï¸  Graph exists â€” skipped: Rome\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Vatican_City\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Fez\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Moscow\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Medellin\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Palmanova\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Dubai\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Canberra\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Los_Angeles\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Randstad\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Greater_Cairo\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Amsterdam\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "\n",
    "    if os.path.exists(gpath):\n",
    "        print(f\"ðŸ—‚ï¸  Graph exists â€” skipped: {city['name']}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸ”„ {city['name']} ({city['network']}, r={city['distance']}m)â€¦\")\n",
    "        G = ox.graph_from_point(city['coordinates'], dist=city['distance'], network_type=city['network'], simplify=True, retain_all=False)\n",
    "        ox.save_graphml(G, gpath)\n",
    "        print(f\"âœ… Saved: {gpath}\")\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed for {city['name']}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65636f52",
   "metadata": {},
   "source": [
    "# --- Node2Vec ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6c6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â© Skipping Rome (already computed)\n",
      "â© Skipping Vatican_City (already computed)\n",
      "â© Skipping Fez (already computed)\n",
      "â© Skipping Moscow (already computed)\n",
      "â© Skipping Medellin (already computed)\n",
      "â© Skipping Palmanova (already computed)\n",
      "â© Skipping Dubai (already computed)\n",
      "â© Skipping Canberra (already computed)\n",
      "â© Skipping Los_Angeles (already computed)\n",
      "â© Skipping Randstad (already computed)\n",
      "â© Skipping Greater_Cairo (already computed)\n",
      "â© Skipping Amsterdam (already computed)\n"
     ]
    }
   ],
   "source": [
    "# Precompute Node2Vec for each city and save to disk (fast later runs)\n",
    "# Files written per city:\n",
    "#   emb_dir/{City}.npz    -> compressed array \"X\" of shape (n_nodes, N2V_DIM)\n",
    "#   emb_dir/{City}.ids    -> one node id per line (order matters)\n",
    "\n",
    "N2V_DIM, N2V_WALKLEN, N2V_NUMWALKS = 32, 15, 8\n",
    "N2V_WINDOW, N2V_MINCOUNT, N2V_BATCHWORDS = 5, 1, 128\n",
    "\n",
    "for city in city_data:\n",
    "    npz_path = os.path.join(emb_dir, f\"{city['name']}.npz\")\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "\n",
    "    # Skip if both embedding and ids already exist\n",
    "    if os.path.exists(npz_path) and os.path.exists(ids_path):\n",
    "        print(f\"â© Skipping {city['name']} (already computed)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"ðŸ™ï¸  Node2Vec: {city['name']}\")\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    G = ox.load_graphml(gpath)\n",
    "\n",
    "    # largest connected component for stable embeddings\n",
    "    H = nx.Graph(G).subgraph(max(nx.connected_components(nx.Graph(G)), key=len)).copy()\n",
    "    node_list = list(H.nodes())  # preserve order!\n",
    "\n",
    "    # Node2Vec\n",
    "    n2v = Node2Vec(\n",
    "        H, dimensions=N2V_DIM, walk_length=N2V_WALKLEN, num_walks=N2V_NUMWALKS,\n",
    "        p=1, q=1, workers=max(1, mp.cpu_count()-1), seed=42, quiet=True\n",
    "    )\n",
    "    model = n2v.fit(window=N2V_WINDOW, min_count=N2V_MINCOUNT, batch_words=N2V_BATCHWORDS)\n",
    "\n",
    "    # Embedding matrix aligned with node_list\n",
    "    X = np.array([model.wv[str(n)] for n in node_list])\n",
    "\n",
    "    # Save embeddings\n",
    "    np.savez_compressed(npz_path, X=X)\n",
    "\n",
    "    # Save node ids\n",
    "    with open(ids_path, \"w\") as f:\n",
    "        for n in node_list:\n",
    "            f.write(f\"{n}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f0cc4",
   "metadata": {},
   "source": [
    "# --- UMAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef23608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ™ï¸  Processing Rome\n",
      "   PCA: 0.0s   UMAP: 16.0s   HDBSCAN: 38.2s   total: 54.6s\n",
      "   clusters: 62, noise: 13345/32269 (41.4%)\n",
      "   Wrote: embeddings/Rome.jpg\n",
      "   Cluster file: embeddings/Rome.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Vatican_City\n",
      "   PCA: 0.0s   UMAP: 1.8s   HDBSCAN: 0.0s   total: 1.9s\n",
      "   clusters: 6, noise: 37/149 (24.8%)\n",
      "   Wrote: embeddings/Vatican_City.jpg\n",
      "   Cluster file: embeddings/Vatican_City.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Fez\n",
      "   PCA: 0.0s   UMAP: 1.1s   HDBSCAN: 0.1s   total: 1.2s\n",
      "   clusters: 16, noise: 531/1506 (35.3%)\n",
      "   Wrote: embeddings/Fez.jpg\n",
      "   Cluster file: embeddings/Fez.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Moscow\n",
      "   PCA: 0.1s   UMAP: 33.5s   HDBSCAN: 486.5s   total: 521.0s\n",
      "   clusters: 105, noise: 56663/107428 (52.7%)\n",
      "   Wrote: embeddings/Moscow.jpg\n",
      "   Cluster file: embeddings/Moscow.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Medellin\n",
      "   PCA: 0.1s   UMAP: 19.7s   HDBSCAN: 187.9s   total: 208.2s\n",
      "   clusters: 76, noise: 38306/69842 (54.8%)\n",
      "   Wrote: embeddings/Medellin.jpg\n",
      "   Cluster file: embeddings/Medellin.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Palmanova\n",
      "   PCA: 0.0s   UMAP: 0.3s   HDBSCAN: 0.0s   total: 0.4s\n",
      "   clusters: 8, noise: 277/678 (40.9%)\n",
      "   Wrote: embeddings/Palmanova.jpg\n",
      "   Cluster file: embeddings/Palmanova.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Dubai\n",
      "   PCA: 0.0s   UMAP: 1.4s   HDBSCAN: 0.1s   total: 1.6s\n",
      "   clusters: 15, noise: 721/1763 (40.9%)\n",
      "   Wrote: embeddings/Dubai.jpg\n",
      "   Cluster file: embeddings/Dubai.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Canberra\n",
      "   PCA: 0.0s   UMAP: 4.2s   HDBSCAN: 7.8s   total: 12.2s\n",
      "   clusters: 34, noise: 7654/14523 (52.7%)\n",
      "   Wrote: embeddings/Canberra.jpg\n",
      "   Cluster file: embeddings/Canberra.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Los_Angeles\n",
      "   PCA: 0.0s   UMAP: 0.1s   HDBSCAN: 0.0s   total: 0.1s\n",
      "   clusters: 5, noise: 60/184 (32.6%)\n",
      "   Wrote: embeddings/Los_Angeles.jpg\n",
      "   Cluster file: embeddings/Los_Angeles.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Randstad\n",
      "   PCA: 0.1s   UMAP: 60.0s   HDBSCAN: 1307.9s   total: 1369.5s\n",
      "   clusters: 129, noise: 98868/183497 (53.9%)\n",
      "   Wrote: embeddings/Randstad.jpg\n",
      "   Cluster file: embeddings/Randstad.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Greater_Cairo\n",
      "   PCA: 0.3s   UMAP: 168.2s   HDBSCAN: 10530.1s   total: 10702.4s\n",
      "   clusters: 211, noise: 261916/466594 (56.1%)\n",
      "   Wrote: embeddings/Greater_Cairo.jpg\n",
      "   Cluster file: embeddings/Greater_Cairo.csv\n",
      "\n",
      "ðŸ™ï¸  Processing Amsterdam\n",
      "   PCA: 0.0s   UMAP: 2.9s   HDBSCAN: 3.4s   total: 6.4s\n",
      "   clusters: 36, noise: 4619/10087 (45.8%)\n",
      "   Wrote: embeddings/Amsterdam.jpg\n",
      "   Cluster file: embeddings/Amsterdam.csv\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from hdbscan import HDBSCAN\n",
    "import multiprocessing as mp\n",
    "\n",
    "# UMAP (for visualization only)\n",
    "UMAP_NEIGHBORS = 12          # â†“ from 15 (smaller = faster)\n",
    "UMAP_MINDIST   = 0.10\n",
    "UMAP_SEED      = 42\n",
    "\n",
    "for city in city_data:\n",
    "    # if city['name'] != \"Amsterdam\": continue\n",
    "\n",
    "    print(f\"\\nðŸ™ï¸  Processing {city['name']}\")\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load saved Node2Vec\n",
    "    X = np.load(os.path.join(emb_dir, f\"{city['name']}.npz\"))[\"X\"].astype(\"float32\")\n",
    "    with open(os.path.join(emb_dir, f\"{city['name']}.ids\")) as f:\n",
    "        node_list = [line.strip() for line in f]\n",
    "    n = len(node_list)\n",
    "\n",
    "    # ---- Prep once: L2-normalize + PCA to 16 dims ----\n",
    "    X_norm = normalize(X, norm=\"l2\")\n",
    "    X_red  = PCA(n_components=16, random_state=0).fit_transform(X_norm)  # speeds UMAP + HDBSCAN\n",
    "    t_pca = perf_counter()\n",
    "\n",
    "    # ---- UMAP on reduced data (Euclidean is faster than cosine here) ----\n",
    "    embed = umap.UMAP(\n",
    "        n_neighbors=UMAP_NEIGHBORS,\n",
    "        min_dist=UMAP_MINDIST,\n",
    "        metric=\"euclidean\",\n",
    "        random_state=UMAP_SEED,\n",
    "        n_epochs=150,              # â†“ from default ~200\n",
    "        low_memory=True,           # reduces memory pressure; can speed for large n\n",
    "        verbose=False\n",
    "    ).fit_transform(X_red)\n",
    "    t_umap = perf_counter()\n",
    "\n",
    "    # ---- HDBSCAN (moderate setting; parallel core distances) ----\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=max(10, int(n ** 0.48)),\n",
    "        min_samples=3,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"leaf\",\n",
    "        cluster_selection_epsilon=0.03,\n",
    "        prediction_data=False,\n",
    "        approx_min_span_tree=True,\n",
    "        gen_min_span_tree=False,\n",
    "        algorithm=\"best\",\n",
    "        core_dist_n_jobs=mp.cpu_count(),\n",
    "    )\n",
    "    labels = clusterer.fit_predict(X_red)   # -1 = noise\n",
    "    t_hdb = perf_counter()\n",
    "\n",
    "    # ---- Colors from global PALETTE ----\n",
    "    uniq = sorted(set(labels) - {-1})\n",
    "    label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "    point_colors = [label2color.get(lbl, NEUTRAL) for lbl in labels]\n",
    "    n_clusters = len(uniq)\n",
    "\n",
    "    # ---- Save embedding image ----\n",
    "    out_jpg = os.path.join(emb_dir, f\"{city['name']}.jpg\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embed[:, 0], embed[:, 1], s=1, c=point_colors, alpha=1, edgecolor='none')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_jpg, dpi=600, bbox_inches=\"tight\", format=\"jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    # ---- Save node â†’ cluster â†’ color ----\n",
    "    csv_path = os.path.join(emb_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"node_id\", \"cluster\", \"color_hex\"])\n",
    "        for nid, lbl, col in zip(node_list, labels, point_colors):\n",
    "            w.writerow([nid, int(lbl), col])\n",
    "\n",
    "    # ---- Timing report ----\n",
    "    noise = int((labels == -1).sum())\n",
    "    print(f\"   PCA: {(t_pca - t0):.1f}s   UMAP: {(t_umap - t_pca):.1f}s   HDBSCAN: {(t_hdb - t_umap):.1f}s   total: {(perf_counter()-t0):.1f}s\")\n",
    "    print(f\"   clusters: {n_clusters}, noise: {noise}/{n} ({noise/n:.1%})\")\n",
    "    print(f\"   Wrote: {out_jpg}\")\n",
    "    print(f\"   Cluster file: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918d23d",
   "metadata": {},
   "source": [
    "# --- Maps ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76365b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€“ Generating map for Romeâ€¦\n",
      "â€“ Generating map for Vatican_Cityâ€¦\n",
      "â€“ Generating map for Fezâ€¦\n",
      "â€“ Generating map for Moscowâ€¦\n",
      "â€“ Generating map for Medellinâ€¦\n",
      "â€“ Generating map for Palmanovaâ€¦\n",
      "â€“ Generating map for Dubaiâ€¦\n",
      "â€“ Generating map for Canberraâ€¦\n",
      "â€“ Generating map for Los_Angelesâ€¦\n",
      "â€“ Generating map for Randstadâ€¦\n",
      "â€“ Generating map for Greater_Cairoâ€¦\n",
      "â€“ Generating map for Amsterdamâ€¦\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    \n",
    "    # if city['name'] != \"Amsterdam\":\n",
    "    #     continue\n",
    "\n",
    "    print(f\"â€“ Generating map for {city['name']}â€¦\")\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    G = ox.load_graphml(gpath)\n",
    "\n",
    "    # Load node -> cluster from CSV produced during embedding\n",
    "    csv_path = os.path.join(emb_dir, f\"{city['name']}.csv\")\n",
    "    node_cluster = {}\n",
    "    if os.path.exists(csv_path):\n",
    "        import csv\n",
    "        with open(csv_path, newline=\"\") as f:\n",
    "            r = csv.DictReader(f)\n",
    "            for row in r:\n",
    "                nid = str(row[\"node_id\"])\n",
    "                node_cluster[nid] = int(row[\"cluster\"])\n",
    "    else:\n",
    "        node_cluster = {}\n",
    "\n",
    "    # Build a stable color mapping from global PALETTE\n",
    "    # (ignore noise = -1, which will be NEUTRAL)\n",
    "    if node_cluster:\n",
    "        uniq = sorted({c for c in node_cluster.values() if c != -1})\n",
    "        label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "        node_color = {nid: label2color.get(lbl, NEUTRAL) if lbl != -1 else NEUTRAL\n",
    "                      for nid, lbl in node_cluster.items()}\n",
    "    else:\n",
    "        node_color = {}\n",
    "\n",
    "    # Project the SAME graph you will plot\n",
    "    G_proj = ox.project_graph(G)\n",
    "\n",
    "    # Build edge colors using both endpoints; color only if clusters match\n",
    "    edges_proj = list(G_proj.edges(keys=True))\n",
    "    if node_color:\n",
    "        edge_colors = []\n",
    "        for u, v, k in edges_proj:\n",
    "            u_id, v_id = str(u), str(v)\n",
    "            cu = node_cluster.get(u_id, None)\n",
    "            cv = node_cluster.get(v_id, None)\n",
    "            if cu is not None and cv is not None and cu == cv and cu != -1:\n",
    "                edge_colors.append(node_color.get(u_id, NEUTRAL))\n",
    "            else:\n",
    "                edge_colors.append(NEUTRAL)\n",
    "    else:\n",
    "        edge_colors = \"black\"\n",
    "\n",
    "    out_png = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    ox.plot_graph(\n",
    "        G_proj,\n",
    "        bgcolor=\"white\",\n",
    "        node_size=0,\n",
    "        edge_color=edge_colors,\n",
    "        edge_linewidth=0.3,\n",
    "        show=False,\n",
    "        save=True,\n",
    "        filepath=out_png,\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9685",
   "metadata": {},
   "source": [
    "# --- Panels ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e2a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Panel created: Rome\n",
      "âœ… Panel created: Vatican_City\n",
      "âœ… Panel created: Fez\n",
      "âœ… Panel created: Moscow\n",
      "âœ… Panel created: Medellin\n",
      "âœ… Panel created: Palmanova\n",
      "âœ… Panel created: Dubai\n",
      "âœ… Panel created: Canberra\n",
      "âœ… Panel created: Los_Angeles\n",
      "âœ… Panel created: Randstad\n",
      "âœ… Panel created: Greater_Cairo\n",
      "âœ… Panel created: Amsterdam\n",
      "ðŸ“„ Exported to: comparison.pdf\n"
     ]
    }
   ],
   "source": [
    "slides = []\n",
    "\n",
    "for city in city_data:\n",
    "    taxonomy_path = os.path.join(tax_dir, f\"{city['taxonomy']}.jpg\")\n",
    "    city_path     = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    embedding_path  = os.path.join(emb_dir, f\"{city['name']}.jpg\")\n",
    "\n",
    "    taxonomy_img = Image.open(taxonomy_path).convert(\"RGB\").resize(thumb_size)\n",
    "    city_img     = Image.open(city_path).convert(\"RGB\").resize(thumb_size)\n",
    "    embedding_img  = Image.open(embedding_path).convert(\"RGB\").resize(thumb_size)\n",
    "\n",
    "    images = [taxonomy_img, city_img, embedding_img]\n",
    "\n",
    "    # Auto panel size (3 images, equal margins)\n",
    "    margin, y = 40, 100\n",
    "    panel_width  = len(images) * thumb_size[0] + (len(images) + 1) * margin\n",
    "    panel_height = thumb_size[1] + 200\n",
    "    panel = Image.new(\"RGB\", (panel_width, panel_height), \"white\")\n",
    "    draw = ImageDraw.Draw(panel)\n",
    "\n",
    "    # Paste images\n",
    "    for i, img in enumerate(images):\n",
    "        x = margin + i * (thumb_size[0] + margin)\n",
    "        panel.paste(img, (x, y))\n",
    "\n",
    "    # Title: name + taxonomy + coordinates + type + radius\n",
    "    coords = f\"({city['coordinates'][0]:.4f}, {city['coordinates'][1]:.4f})\"\n",
    "    title_text = f\"{city['name']} â€” {city['taxonomy']} â€” {coords} - type={city['network']}, r={city['distance']} m\"\n",
    "    tw = draw.textlength(title_text, font=title_font) if hasattr(draw, \"textlength\") else title_font.getsize(title_text)[0]\n",
    "    draw.text(((panel_width - tw) // 2, 20), title_text, font=title_font, fill=\"black\")\n",
    "\n",
    "    slides.append(panel)\n",
    "    print(f\"âœ… Panel created: {city['name']}\")\n",
    "\n",
    "# Export to PDF (all slides)\n",
    "comparison_images_rgb = [img.convert(\"RGB\") for img in slides]\n",
    "comparison_images_rgb[0].save(pdf_file, save_all=True, append_images=comparison_images_rgb[1:], format=\"PDF\")\n",
    "print(f\"ðŸ“„ Exported to: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d543d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Land",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
