{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635387aa",
   "metadata": {},
   "source": [
    "# --- Settings ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cities loaded\n"
     ]
    }
   ],
   "source": [
    "# ---- Imports ----\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "from time import perf_counter\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import umap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from hdbscan import HDBSCAN\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"umap\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib.externals.loky\")\n",
    "\n",
    "# Fast BLAS on Apple Silicon\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# OSMnx settings\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "# Layout params\n",
    "thumb_size = (600, 600)\n",
    "font_size, title_font_size = 20, 26\n",
    "panel_width = 2 * thumb_size[0] + 3 * 40\n",
    "panel_height = thumb_size[1] + 3 * font_size + 80\n",
    "\n",
    "# Fonts\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    title_font = ImageFont.truetype(\"arial.ttf\", title_font_size)\n",
    "except Exception:\n",
    "    font = ImageFont.load_default()\n",
    "    title_font = ImageFont.load_default()\n",
    "\n",
    "# Files & directories\n",
    "pdf_file = \"comparison.pdf\"\n",
    "map_dir, tax_dir, emb_dir, gra_dir, clu_dir = \"maps\", \"taxonomy\", \"embeddings\", \"graphs\", \"clusters\"\n",
    "for d in (map_dir, tax_dir, emb_dir, gra_dir, clu_dir):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---- Colors ----\n",
    "NEUTRAL = \"#CCCCCC\"\n",
    "PALETTE = [\n",
    "    \"#2E1F3C\",  # balanced deep violet\n",
    "    \"#A13F82\",  # balanced magenta\n",
    "    \"#6B3F9B\",  # balanced purple\n",
    "    \"#1D6FAF\",  # balanced blue\n",
    "    \"#3F9FD1\",  # balanced light blue\n",
    "    \"#2E9C90\",  # balanced teal\n",
    "    \"#D8922F\",  # balanced amber\n",
    "    \"#C23B3B\",  # balanced red\n",
    "]\n",
    "\n",
    "# Ensure consistent HEX format\n",
    "PALETTE = [mpl.colors.to_hex(c) for c in PALETTE]\n",
    "\n",
    "city_data=[{\"name\":\"Rome\",\"country\":\"ITA\",\"coordinates\":(41.894096,12.485609),\"distance\":12000,\"group\":\"Archetypal\",\"taxonomy\":\"Radial_Implosion\",\"network\":\"drive\"},{\"name\":\"Vatican_City\",\"country\":\"VAT\",\"coordinates\":(41.902257,12.457421),\"distance\":200,\"group\":\"Archetypal\",\"taxonomy\":\"Elliptical_Implosion\",\"network\":\"all\"},{\"name\":\"Fez\",\"country\":\"MAR\",\"coordinates\":(34.065,-4.973),\"distance\":800,\"group\":\"Archetypal\",\"taxonomy\":\"Organic_Rhizome\",\"network\":\"all\"},{\"name\":\"Moscow\",\"country\":\"RUS\",\"coordinates\":(55.7558,37.6176),\"distance\":60000,\"group\":\"Archetypal\",\"taxonomy\":\"Centralized_Burst\",\"network\":\"drive\"},{\"name\":\"Medellin\",\"country\":\"COL\",\"coordinates\":(6.2518,-75.5836),\"distance\":15000,\"group\":\"Geometrical\",\"taxonomy\":\"Arc_Diagram\",\"network\":\"all\"},{\"name\":\"Palmanova\",\"country\":\"ITA\",\"coordinates\":(45.9061,13.3095),\"distance\":1500,\"group\":\"Geometrical\",\"taxonomy\":\"Radial_Convergence\",\"network\":\"all\"},{\"name\":\"Dubai\",\"country\":\"ARE\",\"coordinates\":(25.056530,55.207939),\"distance\":1000,\"group\":\"Geometrical\",\"taxonomy\":\"Segmented_Radial_Convergence\",\"network\":\"all\"},{\"name\":\"Canberra\",\"country\":\"AUS\",\"coordinates\":(-35.308188,149.124441),\"distance\":3200,\"group\":\"Geometrical\",\"taxonomy\":\"Centralized_Ring\",\"network\":\"all\"},{\"name\":\"Los_Angeles\",\"country\":\"USA\",\"coordinates\":(34.029315,-118.214444),\"distance\":800,\"group\":\"Relational\",\"taxonomy\":\"Flow_Chart\",\"network\":\"drive\"},{\"name\":\"Randstad\",\"country\":\"NLD\",\"coordinates\":(52.1,4.6),\"distance\":40000,\"group\":\"Relational\",\"taxonomy\":\"Area_Grouping\",\"network\":\"drive\"},{\"name\":\"Greater_Cairo\",\"country\":\"EGY\",\"coordinates\":(30.0444,31.2357),\"distance\":50000,\"group\":\"Relational\",\"taxonomy\":\"Circular_Ties\",\"network\":\"drive\"},{\"name\":\"Amsterdam\",\"country\":\"NLD\",\"coordinates\":(52.371,4.90),\"distance\":2000,\"group\":\"Relational\",\"taxonomy\":\"Ramification\",\"network\":\"all\"}]\n",
    "\n",
    "# --- Choose which cities to process ---\n",
    "TARGET_CITIES = None   # None = process all cities\n",
    "# TARGET_CITIES = [\"Amsterdam\"]  # uncomment to process only Amsterdam\n",
    "\n",
    "print(f\"{len(city_data)} cities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc3cf",
   "metadata": {},
   "source": [
    "# --- Graphs ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e2d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‚ï¸  Graph exists â€” skipped: Rome\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Vatican_City\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Fez\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Moscow\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Medellin\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Palmanova\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Dubai\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Canberra\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Los_Angeles\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Randstad\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Greater_Cairo\n",
      "ðŸ—‚ï¸  Graph exists â€” skipped: Amsterdam\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "\n",
    "    if os.path.exists(gpath):\n",
    "        print(f\"ðŸ—‚ï¸  Graph exists â€” skipped: {city['name']}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸ”„ {city['name']} ({city['network']}, r={city['distance']}m)â€¦\")\n",
    "        G = ox.graph_from_point(city['coordinates'], dist=city['distance'], network_type=city['network'], simplify=True, retain_all=False)\n",
    "        ox.save_graphml(G, gpath)\n",
    "        print(f\"âœ… Saved: {gpath}\")\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed for {city['name']}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65636f52",
   "metadata": {},
   "source": [
    "# --- Node2Vec ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6c6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â© Skipping Rome (already computed)\n",
      "â© Skipping Vatican_City (already computed)\n",
      "â© Skipping Fez (already computed)\n",
      "â© Skipping Moscow (already computed)\n",
      "â© Skipping Medellin (already computed)\n",
      "â© Skipping Palmanova (already computed)\n",
      "â© Skipping Dubai (already computed)\n",
      "â© Skipping Canberra (already computed)\n",
      "â© Skipping Los_Angeles (already computed)\n",
      "â© Skipping Randstad (already computed)\n",
      "â© Skipping Greater_Cairo (already computed)\n",
      "â© Skipping Amsterdam (already computed)\n"
     ]
    }
   ],
   "source": [
    "# Precompute Node2Vec for each city and save to disk (fast later runs)\n",
    "# Files written per city:\n",
    "#   emb_dir/{City}.npz    -> compressed array \"X\" of shape (n_nodes, N2V_DIM)\n",
    "#   emb_dir/{City}.ids    -> one node id per line (order matters)\n",
    "\n",
    "N2V_DIM, N2V_WALKLEN, N2V_NUMWALKS = 32, 15, 8\n",
    "N2V_WINDOW, N2V_MINCOUNT, N2V_BATCHWORDS = 5, 1, 128\n",
    "\n",
    "for city in city_data:\n",
    "    npz_path = os.path.join(emb_dir, f\"{city['name']}.npz\")\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "\n",
    "    # Skip if both embedding and ids already exist\n",
    "    if os.path.exists(npz_path) and os.path.exists(ids_path):\n",
    "        print(f\"â© Skipping {city['name']} (already computed)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"ðŸ™ï¸  Node2Vec: {city['name']}\")\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    G = ox.load_graphml(gpath)\n",
    "\n",
    "    # largest connected component for stable embeddings\n",
    "    H = nx.Graph(G).subgraph(max(nx.connected_components(nx.Graph(G)), key=len)).copy()\n",
    "    node_list = list(H.nodes())  # preserve order!\n",
    "\n",
    "    # Node2Vec\n",
    "    n2v = Node2Vec(\n",
    "        H, dimensions=N2V_DIM, walk_length=N2V_WALKLEN, num_walks=N2V_NUMWALKS,\n",
    "        p=1, q=1, workers=max(1, mp.cpu_count()-1), seed=42, quiet=True\n",
    "    )\n",
    "    model = n2v.fit(window=N2V_WINDOW, min_count=N2V_MINCOUNT, batch_words=N2V_BATCHWORDS)\n",
    "\n",
    "    # Embedding matrix aligned with node_list\n",
    "    X = np.array([model.wv[str(n)] for n in node_list])\n",
    "\n",
    "    # Save embeddings\n",
    "    np.savez_compressed(npz_path, X=X)\n",
    "\n",
    "    # Save node ids\n",
    "    with open(ids_path, \"w\") as f:\n",
    "        for n in node_list:\n",
    "            f.write(f\"{n}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f0cc4",
   "metadata": {},
   "source": [
    "# --- UMAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ef23608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ™ï¸  UMAP for Rome\n",
      "   Saved UMAP â†’ embeddings/Rome.npy   (8.6s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Vatican_City\n",
      "   Saved UMAP â†’ embeddings/Vatican_City.npy   (0.0s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Fez\n",
      "   Saved UMAP â†’ embeddings/Fez.npy   (1.0s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Moscow\n",
      "   Saved UMAP â†’ embeddings/Moscow.npy   (27.5s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Medellin\n",
      "   Saved UMAP â†’ embeddings/Medellin.npy   (18.4s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Palmanova\n",
      "   Saved UMAP â†’ embeddings/Palmanova.npy   (0.3s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Dubai\n",
      "   Saved UMAP â†’ embeddings/Dubai.npy   (1.4s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Canberra\n",
      "   Saved UMAP â†’ embeddings/Canberra.npy   (3.7s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Los_Angeles\n",
      "   Saved UMAP â†’ embeddings/Los_Angeles.npy   (0.1s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Randstad\n",
      "   Saved UMAP â†’ embeddings/Randstad.npy   (50.7s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Greater_Cairo\n",
      "   Saved UMAP â†’ embeddings/Greater_Cairo.npy   (166.7s)\n",
      "\n",
      "ðŸ™ï¸  UMAP for Amsterdam\n",
      "   âš¡ Skipping UMAP (already exists)\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    \n",
    "    if TARGET_CITIES is not None and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nðŸ™ï¸  UMAP for {city['name']}\")\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load saved Node2Vec\n",
    "    X = np.load(os.path.join(emb_dir, f\"{city['name']}.npz\"))[\"X\"].astype(\"float32\")\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # Check if UMAP embedding already exists\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "    if os.path.exists(umap_path):\n",
    "        print(f\"   âš¡ Skipping UMAP (already exists)\")\n",
    "        continue\n",
    "\n",
    "    # Prep: normalize + PCA\n",
    "    X_norm = normalize(X, norm=\"l2\")\n",
    "    X_red  = PCA(n_components=16, random_state=0).fit_transform(X_norm)\n",
    "\n",
    "    # Run UMAP\n",
    "    embed = umap.UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.10,\n",
    "        metric=\"euclidean\",\n",
    "        random_state=42,\n",
    "        n_epochs=120,\n",
    "        low_memory=True,\n",
    "        verbose=False\n",
    "    ).fit_transform(X_red)\n",
    "\n",
    "    # Save embedding\n",
    "    np.save(umap_path, embed)\n",
    "    print(f\"   Saved UMAP â†’ {umap_path}   ({(perf_counter()-t0):.1f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eb360",
   "metadata": {},
   "source": [
    "# --- HDBSCAN ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3552a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ™ï¸  HDBSCAN for Amsterdam\n",
      "   HDBSCAN: 0.2s\n",
      "   clusters: 13, noise: 1566/10087 (15.5%)\n",
      "   Wrote: clusters/Amsterdam.jpg\n",
      "   Cluster file: clusters/Amsterdam.csv\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    \n",
    "    if TARGET_CITIES is not None and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nðŸ™ï¸  HDBSCAN for {city['name']}\")\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load node list\n",
    "    with open(os.path.join(emb_dir, f\"{city['name']}.ids\")) as f:\n",
    "        node_list = [line.strip() for line in f]\n",
    "    n = len(node_list)\n",
    "\n",
    "    # Load UMAP embedding\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "    if not os.path.exists(umap_path):\n",
    "        print(f\"   âŒ No UMAP embedding found, skipping.\")\n",
    "        continue\n",
    "    embed = np.load(umap_path)\n",
    "\n",
    "    # Run HDBSCAN\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=max(10, int(n ** 0.60)),\n",
    "        min_samples=3,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"leaf\",\n",
    "        cluster_selection_epsilon=0.1,\n",
    "        prediction_data=False,\n",
    "        approx_min_span_tree=True,\n",
    "        gen_min_span_tree=False,\n",
    "        algorithm=\"best\",\n",
    "        core_dist_n_jobs=mp.cpu_count(),\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embed)\n",
    "\n",
    "    # Colors\n",
    "    uniq = sorted(set(labels) - {-1})\n",
    "    label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "    point_colors = [label2color.get(lbl, NEUTRAL) for lbl in labels]\n",
    "    n_clusters = len(uniq)\n",
    "\n",
    "    # Save image\n",
    "    out_jpg = os.path.join(clu_dir, f\"{city['name']}.jpg\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embed[:, 0], embed[:, 1], s=1, c=point_colors, alpha=1, edgecolor='none')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_jpg, dpi=600, bbox_inches=\"tight\", format=\"jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save CSV\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"node_id\", \"cluster\", \"color_hex\"])\n",
    "        for nid, lbl, col in zip(node_list, labels, point_colors):\n",
    "            w.writerow([nid, int(lbl), col])\n",
    "\n",
    "    # Timing\n",
    "    noise = int((labels == -1).sum())\n",
    "    print(f\"   HDBSCAN: {(perf_counter()-t0):.1f}s\")\n",
    "    print(f\"   clusters: {n_clusters}, noise: {noise}/{n} ({noise/n:.1%})\")\n",
    "    print(f\"   Wrote: {out_jpg}\")\n",
    "    print(f\"   Cluster file: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918d23d",
   "metadata": {},
   "source": [
    "# --- Maps ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76365b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€“ Generating map for Amsterdamâ€¦\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    \n",
    "    if TARGET_CITIES is not None and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    print(f\"â€“ Generating map for {city['name']}â€¦\")\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    G = ox.load_graphml(gpath)\n",
    "\n",
    "    # Load node -> cluster from CSV produced during embedding\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "    node_cluster = {}\n",
    "    if os.path.exists(csv_path):\n",
    "        import csv\n",
    "        with open(csv_path, newline=\"\") as f:\n",
    "            r = csv.DictReader(f)\n",
    "            for row in r:\n",
    "                nid = str(row[\"node_id\"])\n",
    "                node_cluster[nid] = int(row[\"cluster\"])\n",
    "    else:\n",
    "        node_cluster = {}\n",
    "\n",
    "    # Build a stable color mapping from global PALETTE\n",
    "    # (ignore noise = -1, which will be NEUTRAL)\n",
    "    if node_cluster:\n",
    "        uniq = sorted({c for c in node_cluster.values() if c != -1})\n",
    "        label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "        node_color = {nid: label2color.get(lbl, NEUTRAL) if lbl != -1 else NEUTRAL\n",
    "                      for nid, lbl in node_cluster.items()}\n",
    "    else:\n",
    "        node_color = {}\n",
    "\n",
    "    # Project the SAME graph you will plot\n",
    "    G_proj = ox.project_graph(G)\n",
    "\n",
    "    # Build edge colors using both endpoints; color only if clusters match\n",
    "    edges_proj = list(G_proj.edges(keys=True))\n",
    "    if node_color:\n",
    "        edge_colors = []\n",
    "        for u, v, k in edges_proj:\n",
    "            u_id, v_id = str(u), str(v)\n",
    "            cu = node_cluster.get(u_id, None)\n",
    "            cv = node_cluster.get(v_id, None)\n",
    "            if cu is not None and cv is not None and cu == cv and cu != -1:\n",
    "                edge_colors.append(node_color.get(u_id, NEUTRAL))\n",
    "            else:\n",
    "                edge_colors.append(NEUTRAL)\n",
    "    else:\n",
    "        edge_colors = \"black\"\n",
    "\n",
    "    out_png = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    ox.plot_graph(\n",
    "        G_proj,\n",
    "        bgcolor=\"white\",\n",
    "        node_size=0,\n",
    "        edge_color=edge_colors,\n",
    "        edge_linewidth=0.3,\n",
    "        show=False,\n",
    "        save=True,\n",
    "        filepath=out_png,\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9685",
   "metadata": {},
   "source": [
    "# --- Panels ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91e2a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Panel created: Rome\n",
      "âœ… Panel created: Vatican_City\n",
      "âœ… Panel created: Fez\n",
      "âœ… Panel created: Moscow\n",
      "âœ… Panel created: Medellin\n",
      "âœ… Panel created: Palmanova\n",
      "âœ… Panel created: Dubai\n",
      "âœ… Panel created: Canberra\n",
      "âœ… Panel created: Los_Angeles\n",
      "âœ… Panel created: Randstad\n",
      "âœ… Panel created: Greater_Cairo\n",
      "âœ… Panel created: Amsterdam\n",
      "ðŸ“„ Exported to: comparison.pdf\n"
     ]
    }
   ],
   "source": [
    "slides = []\n",
    "\n",
    "for city in city_data:\n",
    "    taxonomy_path = os.path.join(tax_dir, f\"{city['taxonomy']}.jpg\")\n",
    "    city_path     = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    embedding_path  = os.path.join(emb_dir, f\"{city['name']}.jpg\")\n",
    "\n",
    "    taxonomy_img = Image.open(taxonomy_path).convert(\"RGB\").resize(thumb_size)\n",
    "    city_img     = Image.open(city_path).convert(\"RGB\").resize(thumb_size)\n",
    "    embedding_img  = Image.open(embedding_path).convert(\"RGB\").resize(thumb_size)\n",
    "\n",
    "    images = [taxonomy_img, city_img, embedding_img]\n",
    "\n",
    "    # Auto panel size (3 images, equal margins)\n",
    "    margin, y = 40, 100\n",
    "    panel_width  = len(images) * thumb_size[0] + (len(images) + 1) * margin\n",
    "    panel_height = thumb_size[1] + 200\n",
    "    panel = Image.new(\"RGB\", (panel_width, panel_height), \"white\")\n",
    "    draw = ImageDraw.Draw(panel)\n",
    "\n",
    "    # Paste images\n",
    "    for i, img in enumerate(images):\n",
    "        x = margin + i * (thumb_size[0] + margin)\n",
    "        panel.paste(img, (x, y))\n",
    "\n",
    "    # Title: name + taxonomy + coordinates + type + radius\n",
    "    coords = f\"({city['coordinates'][0]:.4f}, {city['coordinates'][1]:.4f})\"\n",
    "    title_text = f\"{city['name']} â€” {city['taxonomy']} â€” {coords} - type={city['network']}, r={city['distance']} m\"\n",
    "    tw = draw.textlength(title_text, font=title_font) if hasattr(draw, \"textlength\") else title_font.getsize(title_text)[0]\n",
    "    draw.text(((panel_width - tw) // 2, 20), title_text, font=title_font, fill=\"black\")\n",
    "\n",
    "    slides.append(panel)\n",
    "    print(f\"âœ… Panel created: {city['name']}\")\n",
    "\n",
    "# Export to PDF (all slides)\n",
    "comparison_images_rgb = [img.convert(\"RGB\") for img in slides]\n",
    "comparison_images_rgb[0].save(pdf_file, save_all=True, append_images=comparison_images_rgb[1:], format=\"PDF\")\n",
    "print(f\"ðŸ“„ Exported to: {pdf_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Land",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
