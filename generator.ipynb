{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635387aa",
   "metadata": {},
   "source": [
    "# --- Settings ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faefc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cities loaded â€¢ target = ALL\n"
     ]
    }
   ],
   "source": [
    "# â€”â€”â€” Imports â€”â€”â€”\n",
    "# Standard library\n",
    "import os, time, json, csv, multiprocessing as mp\n",
    "from time import perf_counter\n",
    "import warnings\n",
    "\n",
    "# Third-party\n",
    "import numpy as np, networkx as nx, osmnx as ox, umap\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from hdbscan import HDBSCAN\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# (Removed unused: pandas, KMeans)\n",
    "\n",
    "# â€”â€”â€” Housekeeping â€”â€”â€”\n",
    "# Quieter logs\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"umap\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib.externals.loky\")\n",
    "\n",
    "# Fast BLAS on Apple Silicon (avoid thread oversubscription)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# â€”â€”â€” Paths â€”â€”â€”\n",
    "pdf_file = \"comparison.pdf\"\n",
    "map_dir, tax_dir, emb_dir, gra_dir, clu_dir = \"maps\", \"taxonomy\", \"embeddings\", \"graphs\", \"clusters\"\n",
    "for d in (map_dir, tax_dir, emb_dir, gra_dir, clu_dir):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# â€”â€”â€” Palette â€”â€”â€” (GSD-inspired earthy mapping)\n",
    "NEUTRAL = \"#CCCCCC\"\n",
    "PALETTE = [\n",
    "    \"#A4653E\",  # brighter terracotta\n",
    "    \"#D9985E\",  # lighter ochre\n",
    "    \"#88B28B\",  # fresher sage green\n",
    "    \"#69A8B2\",  # clearer teal\n",
    "    \"#B2879C\",  # livelier mauve\n",
    "    \"#6A717A\",  # lighter slate gray\n",
    "    \"#E0D3B0\",  # brighter pale stone\n",
    "    \"#9C7384\",  # stronger plum\n",
    "]\n",
    "\n",
    "# â€”â€”â€” Cities â€”â€”â€”\n",
    "city_data = [\n",
    "    {\"name\": \"Rome\", \"country\": \"ITA\",\n",
    "        \"coordinates\": (41.8941, 12.4856), \"distance\": 5000, \"network\": \"drive\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Radial_Implosion\"},  # Old was 12000\n",
    "    {\"name\": \"Vatican_City\", \"country\": \"VAT\",\n",
    "        \"coordinates\": (41.9023, 12.4574), \"distance\": 500, \"network\": \"all\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Elliptical_Implosion\"},\n",
    "    {\"name\": \"Fez\", \"country\": \"MAR\",\n",
    "        \"coordinates\": (34.0650, -4.9730), \"distance\": 1000, \"network\": \"all\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Organic_Rhizome\"},\n",
    "    {\"name\": \"Moscow\", \"country\": \"RUS\",\n",
    "        \"coordinates\": (55.7558, 37.6176), \"distance\": 5000, \"network\": \"drive\",\n",
    "        \"group\": \"Archetypal\", \"taxonomy\": \"Centralized_Burst\"},  # Old was 60000\n",
    "    {\"name\": \"Medellin\", \"country\": \"COL\",\n",
    "        \"coordinates\": (6.2518, -75.5836), \"distance\": 5000, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Arc_Diagram\"},  # Old was 15000\n",
    "    {\"name\": \"Palmanova\", \"country\": \"ITA\",\n",
    "        \"coordinates\": (45.9061, 13.3095), \"distance\": 3000, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Radial_Convergence\"},\n",
    "    {\"name\": \"Dubai\", \"country\": \"ARE\",\n",
    "        \"coordinates\": (25.0565, 55.2070), \"distance\": 1500, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Segmented_Radial_Convergence\"},\n",
    "    {\"name\": \"Canberra\", \"country\": \"AUS\",\n",
    "        \"coordinates\": (-35.3082, 149.1244), \"distance\": 3500, \"network\": \"all\",\n",
    "        \"group\": \"Geometrical\", \"taxonomy\": \"Centralized_Ring\"},\n",
    "    {\"name\": \"Los_Angeles\", \"country\": \"USA\",\n",
    "        \"coordinates\": (34.0293, -118.2144), \"distance\": 1000, \"network\": \"drive\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Flow_Chart\"},\n",
    "    {\"name\": \"Randstad\", \"country\": \"NLD\",\n",
    "        \"coordinates\": (52.1000, 4.6000), \"distance\": 5000, \"network\": \"drive\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Area_Grouping\"}, # Old was 40000\n",
    "    {\"name\": \"Greater_Cairo\", \"country\": \"EGY\",\n",
    "        \"coordinates\": (30.0444, 31.2357), \"distance\": 5000, \"network\": \"drive\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Circular_Ties\"}, # Old was 50000\n",
    "    {\"name\": \"Amsterdam\", \"country\": \"NLD\",\n",
    "        \"coordinates\": (52.3710, 4.9000), \"distance\": 2000, \"network\": \"all\",\n",
    "        \"group\": \"Relational\", \"taxonomy\": \"Ramification\"}\n",
    "]\n",
    "\n",
    "# â€”â€”â€” Selection â€”â€”â€”\n",
    "# None â†’ all cities; else only the ones listed\n",
    "TARGET_CITIES = None\n",
    "# TARGET_CITIES = [\"Dubai\"]\n",
    "\n",
    "print(f\"{len(city_data)} cities loaded â€¢ target = {TARGET_CITIES or 'ALL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fc3cf",
   "metadata": {},
   "source": [
    "# --- Graphs ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e2d411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rome (drive, r=5000m) â€” nodes=10724, edges=20720 â€” saved in 14.7s\n",
      "âœ… Vatican_City (all, r=500m) â€” nodes=1467, edges=3821 â€” saved in 2.7s\n",
      "âœ… Fez (all, r=1000m) â€” nodes=1930, edges=4695 â€” saved in 2.2s\n",
      "âœ… Moscow (drive, r=5000m) â€” nodes=4369, edges=8744 â€” saved in 6.8s\n",
      "âœ… Medellin (all, r=5000m) â€” nodes=31531, edges=82602 â€” saved in 23.5s\n",
      "âœ… Palmanova (all, r=3000m) â€” nodes=1971, edges=4802 â€” saved in 2.5s\n",
      "âœ… Dubai (all, r=1500m) â€” nodes=2762, edges=6506 â€” saved in 3.0s\n",
      "âœ… Canberra (all, r=3500m) â€” nodes=16986, edges=47924 â€” saved in 15.2s\n",
      "âœ… Los_Angeles (drive, r=1000m) â€” nodes=316, edges=784 â€” saved in 0.7s\n",
      "âœ… Randstad (drive, r=5000m) â€” nodes=3722, edges=8663 â€” saved in 4.3s\n",
      "âœ… Greater_Cairo (drive, r=5000m) â€” nodes=40398, edges=101637 â€” saved in 20.5s\n",
      "âœ… Amsterdam (all, r=2000m) â€” nodes=10396, edges=26257 â€” saved in 9.7s\n"
     ]
    }
   ],
   "source": [
    "# OSMnx settings\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = False\n",
    "\n",
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    # if os.path.exists(gpath):\n",
    "    #     print(f\"ğŸ—‚ï¸ {city['name']} skipped (already exists)\")\n",
    "    #     continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    G = ox.graph_from_point(\n",
    "        city['coordinates'],\n",
    "        dist=city['distance'],\n",
    "        network_type=city['network'],\n",
    "        simplify=True,\n",
    "        retain_all=False,\n",
    "        truncate_by_edge=True   # include full edges that cross the boundary\n",
    "    )\n",
    "    ox.save_graphml(G, gpath)\n",
    "    dt = perf_counter() - t0\n",
    "    print(f\"âœ… {city['name']} ({city['network']}, r={city['distance']}m) â€” \"\n",
    "          f\"nodes={G.number_of_nodes()}, edges={G.number_of_edges()} â€” saved in {dt:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65636f52",
   "metadata": {},
   "source": [
    "# --- Node2Vec ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6c6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Rome â€” 10724 nodes, dim=32 â€” 10.1s\n",
      "   âœ… Vatican_City â€” 1467 nodes, dim=32 â€” 1.4s\n",
      "   âœ… Fez â€” 1930 nodes, dim=32 â€” 1.7s\n",
      "   âœ… Moscow â€” 4369 nodes, dim=32 â€” 4.1s\n",
      "   âœ… Medellin â€” 31531 nodes, dim=32 â€” 28.2s\n",
      "   âœ… Palmanova â€” 1971 nodes, dim=32 â€” 2.0s\n",
      "   âœ… Dubai â€” 2762 nodes, dim=32 â€” 2.3s\n",
      "   âœ… Canberra â€” 16986 nodes, dim=32 â€” 14.9s\n",
      "   âœ… Los_Angeles â€” 316 nodes, dim=32 â€” 0.3s\n",
      "   âœ… Randstad â€” 3722 nodes, dim=32 â€” 3.0s\n",
      "   âœ… Greater_Cairo â€” 40398 nodes, dim=32 â€” 35.3s\n",
      "   âœ… Amsterdam â€” 10396 nodes, dim=32 â€” 9.6s\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    npz_path = os.path.join(emb_dir, f\"{city['name']}.npz\")\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load and keep the largest connected component\n",
    "    H = nx.Graph(ox.load_graphml(os.path.join(gra_dir, f\"{city['name']}.graphml\")))\n",
    "    comps = list(nx.connected_components(H))\n",
    "    if not comps:\n",
    "        print(f\"âš ï¸ {city['name']} has no connected component, skipping\")\n",
    "        continue\n",
    "    H = H.subgraph(max(comps, key=len)).copy()\n",
    "    node_list = list(H.nodes())\n",
    "\n",
    "    # Node2Vec sampler\n",
    "    n2v = Node2Vec(\n",
    "        H,\n",
    "        dimensions=32,      # embedding dimensionality\n",
    "        walk_length=15,     # length of each 2nd-order walk\n",
    "        num_walks=8,        # walks per node\n",
    "        p=1.0,              # return parameter\n",
    "        q=0.5,              # in/out parameter (BFS-ish â†’ local)\n",
    "        workers=max(1, mp.cpu_count()-1),\n",
    "        seed=42,\n",
    "        quiet=True\n",
    "    )\n",
    "\n",
    "    # Train skip-gram on the walk corpus\n",
    "    model = n2v.fit(window=5, min_count=1, batch_words=128)\n",
    "\n",
    "    # Embeddings aligned with node_list\n",
    "    X = np.array([model.wv[str(n)] for n in node_list], dtype=np.float32)\n",
    "\n",
    "    # Save artifacts\n",
    "    np.savez_compressed(npz_path, X=X)\n",
    "    with open(ids_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(map(str, node_list)))\n",
    "\n",
    "    print(f\"   âœ… {city['name']} â€” {len(node_list)} nodes, dim={X.shape[1]} â€” {perf_counter()-t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f0cc4",
   "metadata": {},
   "source": [
    "# --- UMAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef23608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ï¸ Rome | PCA 0.0s | UMAP 10.3s â†’ embeddings/Rome.npy\n",
      "ğŸ™ï¸ Vatican_City | PCA 0.0s | UMAP 2.9s â†’ embeddings/Vatican_City.npy\n",
      "ğŸ™ï¸ Fez | PCA 0.0s | UMAP 1.5s â†’ embeddings/Fez.npy\n",
      "ğŸ™ï¸ Moscow | PCA 0.0s | UMAP 1.0s â†’ embeddings/Moscow.npy\n",
      "ğŸ™ï¸ Medellin | PCA 0.0s | UMAP 8.9s â†’ embeddings/Medellin.npy\n",
      "ğŸ™ï¸ Palmanova | PCA 0.0s | UMAP 1.6s â†’ embeddings/Palmanova.npy\n",
      "ğŸ™ï¸ Dubai | PCA 0.0s | UMAP 2.9s â†’ embeddings/Dubai.npy\n",
      "ğŸ™ï¸ Canberra | PCA 0.0s | UMAP 4.6s â†’ embeddings/Canberra.npy\n",
      "ğŸ™ï¸ Los_Angeles | PCA 0.0s | UMAP 0.1s â†’ embeddings/Los_Angeles.npy\n",
      "ğŸ™ï¸ Randstad | PCA 0.0s | UMAP 5.1s â†’ embeddings/Randstad.npy\n",
      "ğŸ™ï¸ Greater_Cairo | PCA 0.0s | UMAP 11.7s â†’ embeddings/Greater_Cairo.npy\n",
      "ğŸ™ï¸ Amsterdam | PCA 0.0s | UMAP 3.0s â†’ embeddings/Amsterdam.npy\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    npz_path  = os.path.join(emb_dir, f\"{city['name']}.npz\")\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "\n",
    "    if not os.path.exists(npz_path):\n",
    "        print(f\"âš ï¸ {city['name']} skipped (no embeddings found)\")\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    X = np.load(npz_path)[\"X\"].astype(\"float32\")\n",
    "\n",
    "    # Normalize + PCA\n",
    "    X_red = PCA(n_components=16, random_state=0).fit_transform(\n",
    "        normalize(X, norm=\"l2\")\n",
    "    )\n",
    "    t_pca = perf_counter()\n",
    "\n",
    "    # UMAP\n",
    "    embed = umap.UMAP(\n",
    "        n_neighbors=8,      # 8 preserves global structure; 5 leaves gaps\n",
    "        min_dist=0.20,      # balance between clumping and spread\n",
    "        metric=\"euclidean\",\n",
    "        random_state=42,\n",
    "        n_epochs=150,\n",
    "        low_memory=True,\n",
    "    ).fit_transform(X_red)\n",
    "\n",
    "    np.save(umap_path, embed)\n",
    "    print(f\"ğŸ™ï¸ {city['name']} | PCA {t_pca-t0:.1f}s | UMAP {perf_counter()-t_pca:.1f}s â†’ {umap_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eb360",
   "metadata": {},
   "source": [
    "# --- HDBSCAN ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3552a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ï¸ Rome | HDBSCAN 0.3s | clusters 6 | noise 3765/10724 (35.1%) â†’ clusters/Rome.csv\n",
      "ğŸ™ï¸ Vatican_City | HDBSCAN 0.1s | clusters 6 | noise 114/1467 (7.8%) â†’ clusters/Vatican_City.csv\n",
      "ğŸ™ï¸ Fez | HDBSCAN 0.1s | clusters 3 | noise 230/1930 (11.9%) â†’ clusters/Fez.csv\n",
      "ğŸ™ï¸ Moscow | HDBSCAN 0.1s | clusters 6 | noise 487/4369 (11.1%) â†’ clusters/Moscow.csv\n",
      "ğŸ™ï¸ Medellin | HDBSCAN 2.1s | clusters 5 | noise 19618/31531 (62.2%) â†’ clusters/Medellin.csv\n",
      "ğŸ™ï¸ Palmanova | HDBSCAN 0.1s | clusters 3 | noise 607/1971 (30.8%) â†’ clusters/Palmanova.csv\n",
      "ğŸ™ï¸ Dubai | HDBSCAN 0.1s | clusters 5 | noise 882/2762 (31.9%) â†’ clusters/Dubai.csv\n",
      "ğŸ™ï¸ Canberra | HDBSCAN 0.4s | clusters 5 | noise 3141/16986 (18.5%) â†’ clusters/Canberra.csv\n",
      "ğŸ™ï¸ Los_Angeles | HDBSCAN 0.1s | clusters 2 | noise 144/316 (45.6%) â†’ clusters/Los_Angeles.csv\n",
      "ğŸ™ï¸ Randstad | HDBSCAN 0.1s | clusters 6 | noise 94/3722 (2.5%) â†’ clusters/Randstad.csv\n",
      "ğŸ™ï¸ Greater_Cairo | HDBSCAN 0.7s | clusters 7 | noise 13962/40398 (34.6%) â†’ clusters/Greater_Cairo.csv\n",
      "ğŸ™ï¸ Amsterdam | HDBSCAN 0.2s | clusters 5 | noise 3117/10396 (30.0%) â†’ clusters/Amsterdam.csv\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load UMAP embedding\n",
    "    umap_path = os.path.join(emb_dir, f\"{city['name']}.npy\")\n",
    "    embed = np.load(umap_path)\n",
    "\n",
    "    # Load node ids; fallback to sequential ids if file is missing\n",
    "    ids_path = os.path.join(emb_dir, f\"{city['name']}.ids\")\n",
    "    with open(ids_path) as f:\n",
    "        node_list = [line.strip() for line in f]\n",
    "\n",
    "    # HDBSCAN on UMAP space (2D)\n",
    "    clusterer = HDBSCAN(\n",
    "        min_cluster_size=max(10, int(len(node_list) ** 0.70)),\n",
    "        min_samples=3,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"leaf\",\n",
    "        cluster_selection_epsilon=0.06,\n",
    "        prediction_data=False,\n",
    "        approx_min_span_tree=True,\n",
    "        gen_min_span_tree=False,\n",
    "        algorithm=\"best\",\n",
    "        core_dist_n_jobs=mp.cpu_count(),\n",
    "    )\n",
    "    labels = clusterer.fit_predict(embed)  # -1 = noise\n",
    "\n",
    "    # Map cluster â†’ color using the GLOBAL PALETTE (stable order)\n",
    "    uniq = sorted(set(labels) - {-1})\n",
    "    label2color = {lab: PALETTE[i % len(PALETTE)] for i, lab in enumerate(uniq)}\n",
    "    point_colors = [label2color.get(lbl, NEUTRAL) for lbl in labels]\n",
    "\n",
    "    # Save colored embedding (for visual checks)\n",
    "    out_jpg = os.path.join(clu_dir, f\"{city['name']}.jpg\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embed[:, 0], embed[:, 1], s=1.5, c=point_colors, alpha=0.9, edgecolor='none')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_jpg, dpi=600, bbox_inches=\"tight\", format=\"jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    # Persist exact colors per node\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"node_id\", \"cluster\", \"color_hex\"])\n",
    "        for nid, lbl, col in zip(node_list, labels, point_colors):\n",
    "            w.writerow([nid, int(lbl), col])\n",
    "\n",
    "    noise = int((labels == -1).sum())\n",
    "    print(f\"ğŸ™ï¸ {city['name']} | HDBSCAN {perf_counter()-t0:.1f}s | clusters {len(uniq)} | noise {noise}/{len(node_list)} ({noise/len(node_list):.1%}) â†’ {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918d23d",
   "metadata": {},
   "source": [
    "# --- Maps ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76365b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ºï¸ Rome | map 3.2s â†’ maps/Rome.png\n",
      "ğŸ—ºï¸ Vatican_City | map 0.5s â†’ maps/Vatican_City.png\n",
      "ğŸ—ºï¸ Fez | map 0.9s â†’ maps/Fez.png\n",
      "ğŸ—ºï¸ Moscow | map 1.5s â†’ maps/Moscow.png\n",
      "ğŸ—ºï¸ Medellin | map 9.9s â†’ maps/Medellin.png\n",
      "ğŸ—ºï¸ Palmanova | map 0.7s â†’ maps/Palmanova.png\n",
      "ğŸ—ºï¸ Dubai | map 1.2s â†’ maps/Dubai.png\n",
      "ğŸ—ºï¸ Canberra | map 5.9s â†’ maps/Canberra.png\n",
      "ğŸ—ºï¸ Los_Angeles | map 0.3s â†’ maps/Los_Angeles.png\n",
      "ğŸ—ºï¸ Randstad | map 1.3s â†’ maps/Randstad.png\n",
      "ğŸ—ºï¸ Greater_Cairo | map 11.8s â†’ maps/Greater_Cairo.png\n",
      "ğŸ—ºï¸ Amsterdam | map 3.4s â†’ maps/Amsterdam.png\n"
     ]
    }
   ],
   "source": [
    "for city in city_data:\n",
    "    if TARGET_CITIES and city['name'] not in TARGET_CITIES:\n",
    "        continue\n",
    "\n",
    "    gpath = os.path.join(gra_dir, f\"{city['name']}.graphml\")\n",
    "    csv_path = os.path.join(clu_dir, f\"{city['name']}.csv\")\n",
    "\n",
    "    if not (os.path.exists(gpath) and os.path.exists(csv_path)):\n",
    "        print(f\"âš ï¸ {city['name']} skipped (graph or clusters missing)\")\n",
    "        continue\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    # Load graph\n",
    "    G = ox.load_graphml(gpath)\n",
    "\n",
    "    # Load cluster labels + colors\n",
    "    node_cluster, node_color = {}, {}\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            nid = str(row[\"node_id\"])\n",
    "            node_cluster[nid] = int(row[\"cluster\"])\n",
    "            node_color[nid]   = row.get(\"color_hex\") or NEUTRAL\n",
    "\n",
    "    # Project graph\n",
    "    G_proj = ox.project_graph(G)\n",
    "\n",
    "    # Edge coloring\n",
    "    edge_colors = []\n",
    "    for u, v, k in G_proj.edges(keys=True):\n",
    "        cu, cv = node_cluster.get(str(u), -1), node_cluster.get(str(v), -1)\n",
    "        if cu == cv and cu != -1:\n",
    "            edge_colors.append(node_color.get(str(u), NEUTRAL))\n",
    "        else:\n",
    "            edge_colors.append(NEUTRAL)\n",
    "\n",
    "    # Save map\n",
    "    out_png = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    fig, ax = ox.plot_graph(\n",
    "        G_proj,\n",
    "        bgcolor=\"white\",\n",
    "        node_size=0,\n",
    "        edge_color=edge_colors,\n",
    "        edge_linewidth=0.4,\n",
    "        show=False,\n",
    "        save=True,\n",
    "        filepath=out_png,\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"ğŸ—ºï¸ {city['name']} | map {perf_counter()-t0:.1f}s â†’ {out_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9685",
   "metadata": {},
   "source": [
    "# --- Panels ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e2a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Exported to: comparison.pdf\n"
     ]
    }
   ],
   "source": [
    "# Layout params\n",
    "thumb_size = (1500, 1500)\n",
    "FONT_SIZE  = 40                 # one font size for everything\n",
    "margin     = 40\n",
    "title_y    = 20                  # top padding for the title\n",
    "\n",
    "# Try a few common fonts; fall back to PIL default if none found\n",
    "font = None\n",
    "for fp in [\"arial.ttf\", \"Arial.ttf\", \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
    "           \"/System/Library/Fonts/Supplemental/Arial Unicode.ttf\",\n",
    "           \"/Library/Fonts/Arial.ttf\", \"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\"]:\n",
    "    try:\n",
    "        font = ImageFont.truetype(fp, FONT_SIZE)\n",
    "        break\n",
    "    except Exception:\n",
    "        continue\n",
    "if font is None:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "def text_width(draw, text, font):\n",
    "    if hasattr(draw, \"textlength\"):\n",
    "        return draw.textlength(text, font=font)\n",
    "    # Fallback: use bbox width\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    return bbox[2] - bbox[0]\n",
    "\n",
    "slides = []\n",
    "\n",
    "for city in city_data:\n",
    "    city_path     = os.path.join(map_dir, f\"{city['name']}.png\")\n",
    "    clusters_path = os.path.join(clu_dir, f\"{city['name']}.jpg\")\n",
    "\n",
    "    city_img     = Image.open(city_path).convert(\"RGB\").resize(thumb_size, Image.LANCZOS)\n",
    "    clusters_img = Image.open(clusters_path).convert(\"RGB\").resize(thumb_size, Image.LANCZOS)\n",
    "\n",
    "    images = [city_img, clusters_img]\n",
    "\n",
    "    # Panel size\n",
    "    panel_width  = len(images) * thumb_size[0] + (len(images) + 1) * margin\n",
    "    panel_height = thumb_size[1] + FONT_SIZE + 120  # room for big title\n",
    "    panel = Image.new(\"RGB\", (panel_width, panel_height), \"white\")\n",
    "    draw = ImageDraw.Draw(panel)\n",
    "\n",
    "    # Paste images\n",
    "    y = title_y + FONT_SIZE + 40\n",
    "    for i, img in enumerate(images):\n",
    "        x = margin + i * (thumb_size[0] + margin)\n",
    "        panel.paste(img, (x, y))\n",
    "\n",
    "    # Title: name + taxonomy + coordinates + type + radius\n",
    "    coords = f\"({city['coordinates'][0]:.4f}, {city['coordinates'][1]:.4f})\"\n",
    "    title_text = f\"{city['name']} â€” {city['taxonomy']} â€” {coords}  â€¢  type={city['network']}, r={city['distance']} m\"\n",
    "    tw = text_width(draw, title_text, font)\n",
    "    draw.text(((panel_width - tw) // 2, title_y), title_text, font=font, fill=\"black\")\n",
    "\n",
    "    slides.append(panel)\n",
    "\n",
    "# Export to PDF (all slides)\n",
    "comparison_images_rgb = [img.convert(\"RGB\") for img in slides]\n",
    "comparison_images_rgb[0].save(pdf_file, save_all=True, append_images=comparison_images_rgb[1:], format=\"PDF\")\n",
    "print(f\"ğŸ“„ Exported to: {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a554be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Land",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
